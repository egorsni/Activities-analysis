{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "colab": {
      "name": "sem03_kaggle_train.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5EhTGM6MMmae",
        "outputId": "5c4eaa4a-cb84-4960-b638-70da539a888e"
      },
      "source": [
        "import pandas as pd\n",
        "from matplotlib import pylab as plt\n",
        "%pylab inline"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Populating the interactive namespace from numpy and matplotlib\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/IPython/core/magics/pylab.py:161: UserWarning: pylab import has clobbered these variables: ['plt']\n",
            "`%matplotlib` prevents importing * from pylab and numpy\n",
            "  \"\\n`%matplotlib` prevents importing * from pylab and numpy\"\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WmcDRPMcMo8y",
        "outputId": "03b4c3bd-1ea0-43ff-d241-eaf837d229da"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mvJJi_2T0DHd"
      },
      "source": [
        ""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9yDkazTwMmaf"
      },
      "source": [
        "## 1. Создание предсказательной модели и оценивание её качества."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_LNrFfFxMmah"
      },
      "source": [
        "Считаем данные из скачанной открытой гугл-папки"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "suUN-kLOMmai"
      },
      "source": [
        "import os\n",
        "import pandas as pd\n",
        "path = r'drive/MyDrive/dropbox' \n",
        "data = {}\n",
        "\n",
        "Data = []\n",
        "Target = []\n",
        "\n",
        "i=0\n",
        "for dir_entry in sorted(os.listdir(path)):\n",
        "    dir_entry_path = os.path.join(path, dir_entry)\n",
        "    if os.path.isfile(dir_entry_path):\n",
        "        i+=1\n",
        "        with open(dir_entry_path, 'r') as my_file:\n",
        "            try:\n",
        "                df = pd.read_csv(my_file, delimiter=';')\n",
        "                if df.shape[1] == 5:\n",
        "                    Data.append(df)\n",
        "                    Target.append(dir_entry_path.split(\"\\\\\")[-1])\n",
        "                else:\n",
        "                    if df.shape[1] != 1:\n",
        "                        print(dir_entry_path.split(\"\\\\\")[-1], df.shape[1])\n",
        "            except:\n",
        "                pass\n",
        "\n",
        "for dir_entry in sorted(os.listdir(path)):\n",
        "    dir_entry_path = os.path.join(path, dir_entry)\n",
        "    if os.path.isfile(dir_entry_path):\n",
        "        i+=1\n",
        "        with open(dir_entry_path, 'r') as my_file:\n",
        "            try:\n",
        "                df = pd.read_csv(my_file, delimiter=',')\n",
        "                if df.shape[1] == 5:\n",
        "                    Data.append(df)\n",
        "                    Target.append(dir_entry_path.split(\"\\\\\")[-1])\n",
        "                else:\n",
        "                    if df.shape[1] != 1:\n",
        "                        print(dir_entry_path.split(\"\\\\\")[-1], df.shape[1])\n",
        "            except:\n",
        "                pass"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GgydcM7dMmai",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e84ff558-db49-40a5-ab79-f62a414f4224"
      },
      "source": [
        "print(len(Target))"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1301\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rJvhuMoPMmaj"
      },
      "source": [
        "def rotation_matrix_from_vectors(vec1, vec2):\n",
        "    \"\"\" Find the rotation matrix that aligns vec1 to vec2\n",
        "    :param vec1: A 3d \"source\" vector\n",
        "    :param vec2: A 3d \"destination\" vector\n",
        "    :return mat: A transform matrix (3x3) which when applied to vec1, aligns it with vec2.\n",
        "    \"\"\"\n",
        "    a, b = (vec1 / numpy.linalg.norm(vec1)).reshape(3), (vec2 / numpy.linalg.norm(vec2)).reshape(3)\n",
        "    v = numpy.cross(a, b)\n",
        "    if any(v): #if not all zeros then \n",
        "        c = numpy.dot(a, b)\n",
        "        s = numpy.linalg.norm(v)\n",
        "        kmat = numpy.array([[0, -v[2], v[1]], [v[2], 0, -v[0]], [-v[1], v[0], 0]])\n",
        "        return numpy.eye(3) + kmat + kmat.dot(kmat) * ((1 - c) / (s ** 2))\n",
        "\n",
        "    else:\n",
        "        return numpy.eye(3) #cross of all zeros only occurs on identical directions"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "p4z57rpkMmaj"
      },
      "source": [
        "def rotate(X, Y, Z, Mat):\n",
        "    new_x = []\n",
        "    new_y = []\n",
        "    new_z = []\n",
        "    \n",
        "    for elem in zip(X,Y,Z):\n",
        "        res = Mat.dot(elem)\n",
        "        new_x.append(res[0])\n",
        "        new_y.append(res[1])\n",
        "        new_z.append(res[2])\n",
        "        \n",
        "    return new_x, new_y, new_z"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2duu9O8lMmak"
      },
      "source": [
        "def integrate(lst):\n",
        "    res = []\n",
        "    s = 0\n",
        "    for elem in lst:\n",
        "        s += elem\n",
        "        res.append(s)\n",
        "    return res"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ze9ts4a-Mmak"
      },
      "source": [
        ""
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "f_mdY3plMmak"
      },
      "source": [
        "Переведём типы движений в числа"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8kn5mrKdMmak"
      },
      "source": [
        "classes = {'тояни' : 0, 'месте' : 0,\n",
        "           'одьб' : 1,'go':1,'стою':1,'покой':1, 'аг' : 1,'stoyat':1,'стойка':1,\n",
        "           'ег' : 2,'run':2, 'елоси' : 3,\n",
        "           'естн' : 4, 'одъ' : 4, 'stairs':4,\n",
        "            'втомо' : 5, 'авто':5, 'ашин' : 5,\n",
        "           'метро' : 6,\n",
        "           'лектро' : 7,\n",
        "           'амок' : 8}\n",
        "\n",
        "answers = {'стояние' : 0, 'ходьба' : 1, 'бег' : 2, 'велосипед' : 3, 'лестница' : 4, \n",
        "           'автомобиль' : 5, 'метро' : 6, 'электросамокат' : 7, 'самокат' : 8}\n",
        "\n",
        "# стояние, ходьба, велосипед, лестница, бег, подъем, подъём, автомобиль, электросамокат, машина, метро"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "f3SPOfsGMmak"
      },
      "source": [
        "def get_action(name):\n",
        "    for act in classes:\n",
        "        if name.lower().find(act) != -1:\n",
        "            return classes[act]\n",
        "    print(name)\n",
        "    return -1"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VD605PHwMmal",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7dee170d-7b9d-4edb-d16c-19ac9d5bd3b9"
      },
      "source": [
        "answer = [get_action(target) for target in Target]\n",
        "len(Data), len(answer), len(Target)"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "drive/MyDrive/dropbox/Игорь Полежаев - Полежаев электричка 1\n",
            "drive/MyDrive/dropbox/Игорь Полежаев - Полежаев электричка 2\n",
            "drive/MyDrive/dropbox/Игорь Полежаев - Полежаев электричка 3\n",
            "drive/MyDrive/dropbox/Игорь Полежаев - Полежаев электричка 4\n",
            "drive/MyDrive/dropbox/Игорь Полежаев - Полежаев электричка 5\n",
            "drive/MyDrive/dropbox/Дмитрий Тихановский - sensor Тихановский скейтборд.csv\n",
            "drive/MyDrive/dropbox/Дмитрий Тихановский - sensor2 Тихановский скейтборд.csv\n",
            "drive/MyDrive/dropbox/Дмитрий Тихановский - sensor3 Тихановский скейтборд.csv\n",
            "drive/MyDrive/dropbox/Дмитрий Тихановский - sensor4 Тихановский скейтборд.csv\n",
            "drive/MyDrive/dropbox/Дмитрий Тихановский - sensor5 Тихановский скейтборд.csv\n",
            "drive/MyDrive/dropbox/Евгений Измоденов - Измоденов стойка 1.csv\n",
            "drive/MyDrive/dropbox/Евгений Измоденов - Измоденов стойка 2.csv\n",
            "drive/MyDrive/dropbox/Евгений Измоденов - Измоденов стойка 3.csv\n",
            "drive/MyDrive/dropbox/Евгений Измоденов - Измоденов стойка 4.csv\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(1301, 1301, 1301)"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "02UKUpA3Mmal"
      },
      "source": [
        "Обработаем данные и извлечём признаки для создания модели"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "c97n_C_UMmal",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 69
        },
        "outputId": "868d4dd7-e5d6-41df-c94e-ae7026bdb9b3"
      },
      "source": [
        "Data_train = pd.DataFrame(data = {'Ampl':[], 'Moving_x':[], 'Moving_y':[],'Moving_z':[], 'max_freq_a':[],\n",
        "                                  'max_freq_x':[], 'max_freq_y':[],'max_freq_z':[],\n",
        "                                  'mean_freq_x':[], 'mean_freq_y':[],'mean_freq_z':[],\n",
        "                                  'answer':[]})\n",
        "Data_train"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Ampl</th>\n",
              "      <th>Moving_x</th>\n",
              "      <th>Moving_y</th>\n",
              "      <th>Moving_z</th>\n",
              "      <th>max_freq_a</th>\n",
              "      <th>max_freq_x</th>\n",
              "      <th>max_freq_y</th>\n",
              "      <th>max_freq_z</th>\n",
              "      <th>mean_freq_x</th>\n",
              "      <th>mean_freq_y</th>\n",
              "      <th>mean_freq_z</th>\n",
              "      <th>answer</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "Empty DataFrame\n",
              "Columns: [Ampl, Moving_x, Moving_y, Moving_z, max_freq_a, max_freq_x, max_freq_y, max_freq_z, mean_freq_x, mean_freq_y, mean_freq_z, answer]\n",
              "Index: []"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0ztIFiOGMmal",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c879dea0-43db-4ec4-9203-33c133f8c9dc"
      },
      "source": [
        "import pandas as pd\n",
        "from matplotlib import pylab as plt\n",
        "%pylab inline"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Populating the interactive namespace from numpy and matplotlib\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/IPython/core/magics/pylab.py:161: UserWarning: pylab import has clobbered these variables: ['plt']\n",
            "`%matplotlib` prevents importing * from pylab and numpy\n",
            "  \"\\n`%matplotlib` prevents importing * from pylab and numpy\"\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "scrolled": true,
        "id": "PbHJeDRDMmal"
      },
      "source": [
        "def max_x_by_y(x, y):\n",
        "    max_y = 0\n",
        "    res = x[0]\n",
        "    for i in range(0, len(y)):\n",
        "        if y[i] > max_y and x[i] <= 30 and y[i] <= 0.1:\n",
        "            res = x[i]\n",
        "            max_y = y[i]\n",
        "    return res\n",
        "\n",
        "def process_data(df, comma=True, cut=True, name = \"\", a=-1, b=-1, answer=-1):\n",
        "    if answer == -1:\n",
        "        return -1\n",
        "#     fig, ((ax1, ax2, ax3),(ax4, ax5, ax6),(ax7, ax8, ax9)) = plt.subplots(nrows=3, ncols=3, figsize=(15,10))\n",
        "    st = 0\n",
        "    end = len(df)\n",
        "    if comma is True:\n",
        "        df = df.applymap(lambda x: str(x).replace(',','.'))\n",
        "        try:\n",
        "            df['gFx'] = df['gFx'].astype(float)\n",
        "            df['gFy'] = df['gFy'].astype(float)\n",
        "            df['gFz'] = df['gFz'].astype(float)\n",
        "            df['time'] = df['time'].astype(float)\n",
        "        except :\n",
        "            return -1\n",
        "        \n",
        "#     print(name)\n",
        "    # обрезаем начало и конец трека\n",
        "    duration = max(df.time)\n",
        "    df = df[(df.time > 10) & (df.time < duration - 10)]\n",
        "    \n",
        "    if (len(df) ==0):\n",
        "        return -1\n",
        "    \n",
        "    # определим частоту\n",
        "    freqs = np.array(df.time[1:]) - np.array(df.time[:-1])\n",
        "    freq = 1/np.mean(freqs)\n",
        "    \n",
        "    \n",
        "#     ax1.plot(df.time, df.iloc[st:end]['gFx'],c='g')\n",
        "#     ax1.plot(df.time, df.iloc[st:end]['gFy'],c='r')\n",
        "#     ax1.plot(df.time, df.iloc[st:end]['gFz'],c='b')\n",
        "#     ax1.set_title('gFx, gFy, gFz по времени')\n",
        "    \n",
        "#        show()\n",
        "########################################################################        \n",
        "#integration\n",
        "\n",
        "#вычисляем средний вектор ускорения по треку\n",
        "\n",
        "    mx = df.iloc[st:end]['gFx'].values.mean() \n",
        "    my = df.iloc[st:end]['gFy'].values.mean() \n",
        "    mz = df.iloc[st:end]['gFz'].values.mean() \n",
        "    \n",
        "#находим матрицу поворота этого вектора к вектору (0,0,1)\n",
        "\n",
        "    Vec = [mx,my,mz]\n",
        "    Point = [0, 0, 1]\n",
        "    mat = rotation_matrix_from_vectors(Vec, Point)\n",
        "    \n",
        "#каждую точку трека поворачиваем на эту матрицу\n",
        "\n",
        "    new_x, new_y, new_z = rotate(df.iloc[st:end]['gFx'].values, df.iloc[st:end]['gFy'].values, df.iloc[st:end]['gFz'].values, mat)\n",
        "\n",
        "#проверяем, что новые средние равны примерно (0,0,1). Если это не так, значит, телефон часто поворачивался при движении, и нам не поможет это преобразование\n",
        "\n",
        "#     print('New means:', mean(new_x), mean(new_y), mean(new_z))\n",
        "\n",
        "#делим на 250*250 (это нужно было еще при интегрировании)\n",
        "    new_x = [elem / (freq**2) for elem in new_x]\n",
        "    new_y = [elem / (freq**2) for elem in new_y]\n",
        "#из ускорения по z вычитаем 1 (g), чтобы убрать влияние силы тяжести и оставить только ускорение по z\n",
        "    new_z = [(elem-1)/(freq**2) for elem in new_z]\n",
        "    \n",
        "#дважды интегрируем ускорение, чтобы получить перемещение вдоль каждой оси\n",
        "\n",
        "    int_x = integrate(integrate(new_x))\n",
        "#     ax7.plot(int_x)\n",
        "#     ax7.set_title(\"Перемещение по x\")\n",
        "    moving_x = int_x[-1]\n",
        "    \n",
        "    int_y = integrate(integrate(new_y))\n",
        "#     ax8.plot(int_y)\n",
        "#     ax8.set_title(\"Перемещение по y\")\n",
        "    moving_y = int_y[-1]\n",
        "    \n",
        "    int_z = integrate(integrate(new_z))\n",
        "#     ax9.plot(int_z)\n",
        "#     ax9.set_title(\"Перемещение по z\")\n",
        "    moving_z = int_z[-1]\n",
        "\n",
        "########################################################################        \n",
        "#преобразование Фурье\n",
        "########################################################################        \n",
        "\n",
        "    Fs = freq #частота сбора данных\n",
        "    y = df.iloc[st:end]['gFx'].values\n",
        "    n = len(y) # length of the signal\n",
        "    k = np.arange(n)\n",
        "    T = n/Fs\n",
        "    frq = k/T # two sides frequency range\n",
        "    frq = frq[:len(frq)//2] # one side frequency range\n",
        "\n",
        "    Y = np.fft.fft(y)/n # dft and normalization\n",
        "    Y = Y[:n//2]\n",
        "    \n",
        "    yabs = abs(Y)\n",
        "    \n",
        "    Min = 0\n",
        "    \n",
        "    max_frq_x = max_x_by_y(frq,yabs)\n",
        "    \n",
        "    mean_frq_x = np.mean(frq)\n",
        "\n",
        "    \n",
        "    y = df.iloc[st:end]['gFy'].values\n",
        "    n = len(y) # length of the signal\n",
        "    k = np.arange(n)\n",
        "    T = n/Fs\n",
        "    frq = k/T # two sides frequency range\n",
        "    frq = frq[:len(frq)//2] # one side frequency range\n",
        "\n",
        "    Y = np.fft.fft(y)/n # dft and normalization\n",
        "    Y = Y[:n//2]\n",
        "    \n",
        "    yabs = abs(Y)\n",
        "    \n",
        "    max_frq_y = max_x_by_y(frq,yabs)\n",
        "    mean_frq_y = np.mean(frq)\n",
        "\n",
        "\n",
        "    y = df.iloc[st:end]['gFz'].values\n",
        "    n = len(y) # length of the signal\n",
        "    k = np.arange(n)\n",
        "    T = n/Fs\n",
        "    frq = k/T # two sides frequency range\n",
        "    frq = frq[:len(frq)//2] # one side frequency range\n",
        "\n",
        "    Y = np.fft.fft(y)/n # dft and normalization\n",
        "    Y = Y[:n//2]\n",
        "    \n",
        "    yabs = abs(Y)\n",
        "   \n",
        "    max_frq_z = max_x_by_y(frq,yabs)\n",
        "    mean_frq_z = np.mean(frq)\n",
        "\n",
        "\n",
        "    Acc = (df.gFx[st:end] ** 2 + df.gFy[st:end] ** 2 + df.gFz[st:end] ** 2) ** 0.5\n",
        "\n",
        "    y = Acc.values\n",
        "    n = len(y) # length of the signal\n",
        "    k = np.arange(n)\n",
        "    T = n/Fs\n",
        "    frq = k/T # two sides frequency range\n",
        "    frq = frq[:len(frq)//2] # one side frequency range\n",
        "\n",
        "    Y = np.fft.fft(y)/n # dft and normalization\n",
        "    Y = Y[:n//2]\n",
        "    \n",
        "    yabs = abs(Y)\n",
        "    \n",
        "\n",
        "    max_frq_a = max_x_by_y(frq,yabs)\n",
        "########################################################################        \n",
        "    \n",
        "    Acc = (df.gFx[st:end] ** 2 + df.gFy[st:end] ** 2 + df.gFz[st:end] ** 2) ** 0.5\n",
        "    amplitude = Acc.max() - Acc.min()\n",
        "\n",
        "    Data_train.loc[len(Data_train)] = [amplitude,abs(moving_x),abs(moving_y),abs(moving_z),\n",
        "                                       max_frq_a,max_frq_x,max_frq_y,max_frq_z,\n",
        "                                       mean_frq_x,mean_frq_y,mean_frq_z,\n",
        "                                       int(answer)]\n",
        "    \n",
        "    return df\n",
        "\n",
        "for df, target, ans in zip(Data,Target,answer):\n",
        "    process_data(df=df, name=target, answer=ans)"
      ],
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6SsBOdXSMmap",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 689
        },
        "outputId": "7508c604-4fe8-467e-849d-875aa1cb5fac"
      },
      "source": [
        "Data_train.head(20)"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Ampl</th>\n",
              "      <th>Moving_x</th>\n",
              "      <th>Moving_y</th>\n",
              "      <th>Moving_z</th>\n",
              "      <th>max_freq_a</th>\n",
              "      <th>max_freq_x</th>\n",
              "      <th>max_freq_y</th>\n",
              "      <th>max_freq_z</th>\n",
              "      <th>mean_freq_x</th>\n",
              "      <th>mean_freq_y</th>\n",
              "      <th>mean_freq_z</th>\n",
              "      <th>answer</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0.062103</td>\n",
              "      <td>0.152437</td>\n",
              "      <td>0.468787</td>\n",
              "      <td>4.974500</td>\n",
              "      <td>4.732512</td>\n",
              "      <td>0.122393</td>\n",
              "      <td>2.896624</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>125.003590</td>\n",
              "      <td>125.003590</td>\n",
              "      <td>125.003590</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0.200008</td>\n",
              "      <td>0.081242</td>\n",
              "      <td>0.509455</td>\n",
              "      <td>4.234332</td>\n",
              "      <td>2.811671</td>\n",
              "      <td>2.767739</td>\n",
              "      <td>4.393237</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>125.009549</td>\n",
              "      <td>125.009549</td>\n",
              "      <td>125.009549</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0.181625</td>\n",
              "      <td>0.103494</td>\n",
              "      <td>1.133002</td>\n",
              "      <td>2.816271</td>\n",
              "      <td>4.607789</td>\n",
              "      <td>2.912970</td>\n",
              "      <td>4.607789</td>\n",
              "      <td>0.052963</td>\n",
              "      <td>124.992891</td>\n",
              "      <td>124.992891</td>\n",
              "      <td>124.992891</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0.069663</td>\n",
              "      <td>2.406644</td>\n",
              "      <td>0.770164</td>\n",
              "      <td>13.714065</td>\n",
              "      <td>4.024148</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>4.024148</td>\n",
              "      <td>0.072290</td>\n",
              "      <td>125.001594</td>\n",
              "      <td>125.001594</td>\n",
              "      <td>125.001594</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0.399522</td>\n",
              "      <td>32.343050</td>\n",
              "      <td>2.207324</td>\n",
              "      <td>10.244277</td>\n",
              "      <td>5.985661</td>\n",
              "      <td>0.022587</td>\n",
              "      <td>0.022587</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>124.998667</td>\n",
              "      <td>124.998667</td>\n",
              "      <td>124.998667</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>1.449805</td>\n",
              "      <td>0.801564</td>\n",
              "      <td>23.829840</td>\n",
              "      <td>0.055366</td>\n",
              "      <td>1.679955</td>\n",
              "      <td>1.679955</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>1.708920</td>\n",
              "      <td>125.011831</td>\n",
              "      <td>125.011831</td>\n",
              "      <td>125.011831</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>1.738185</td>\n",
              "      <td>1.522133</td>\n",
              "      <td>23.404211</td>\n",
              "      <td>0.843563</td>\n",
              "      <td>3.465310</td>\n",
              "      <td>3.465310</td>\n",
              "      <td>1.732655</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>125.005967</td>\n",
              "      <td>125.005967</td>\n",
              "      <td>125.005967</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>2.703319</td>\n",
              "      <td>14.396613</td>\n",
              "      <td>0.989242</td>\n",
              "      <td>0.020623</td>\n",
              "      <td>1.685900</td>\n",
              "      <td>1.685900</td>\n",
              "      <td>1.685900</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>125.011465</td>\n",
              "      <td>125.011465</td>\n",
              "      <td>125.011465</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>1.474270</td>\n",
              "      <td>13.022342</td>\n",
              "      <td>49.106109</td>\n",
              "      <td>0.791074</td>\n",
              "      <td>1.650967</td>\n",
              "      <td>1.688067</td>\n",
              "      <td>1.688067</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>125.000438</td>\n",
              "      <td>125.000438</td>\n",
              "      <td>125.000438</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>3.496564</td>\n",
              "      <td>2.614811</td>\n",
              "      <td>0.271458</td>\n",
              "      <td>29.609548</td>\n",
              "      <td>1.180885</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>1.180885</td>\n",
              "      <td>1.296658</td>\n",
              "      <td>99.993186</td>\n",
              "      <td>99.993186</td>\n",
              "      <td>99.993186</td>\n",
              "      <td>3.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10</th>\n",
              "      <td>0.881452</td>\n",
              "      <td>0.096376</td>\n",
              "      <td>0.012329</td>\n",
              "      <td>0.066733</td>\n",
              "      <td>1.212210</td>\n",
              "      <td>0.606105</td>\n",
              "      <td>1.212210</td>\n",
              "      <td>1.212210</td>\n",
              "      <td>99.704311</td>\n",
              "      <td>99.704311</td>\n",
              "      <td>99.704311</td>\n",
              "      <td>3.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11</th>\n",
              "      <td>3.656799</td>\n",
              "      <td>5.928100</td>\n",
              "      <td>7.905616</td>\n",
              "      <td>50.105779</td>\n",
              "      <td>2.307660</td>\n",
              "      <td>2.307660</td>\n",
              "      <td>1.552426</td>\n",
              "      <td>2.307660</td>\n",
              "      <td>99.984625</td>\n",
              "      <td>99.984625</td>\n",
              "      <td>99.984625</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>12</th>\n",
              "      <td>3.829502</td>\n",
              "      <td>3.287389</td>\n",
              "      <td>0.757327</td>\n",
              "      <td>17.645230</td>\n",
              "      <td>1.543498</td>\n",
              "      <td>3.164171</td>\n",
              "      <td>1.543498</td>\n",
              "      <td>1.543498</td>\n",
              "      <td>99.980087</td>\n",
              "      <td>99.980087</td>\n",
              "      <td>99.980087</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>13</th>\n",
              "      <td>5.722513</td>\n",
              "      <td>1.970641</td>\n",
              "      <td>0.861193</td>\n",
              "      <td>16.540171</td>\n",
              "      <td>1.560026</td>\n",
              "      <td>1.527526</td>\n",
              "      <td>0.780013</td>\n",
              "      <td>1.560026</td>\n",
              "      <td>99.987938</td>\n",
              "      <td>99.987938</td>\n",
              "      <td>99.987938</td>\n",
              "      <td>4.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>14</th>\n",
              "      <td>0.024133</td>\n",
              "      <td>0.935009</td>\n",
              "      <td>0.224295</td>\n",
              "      <td>2.886693</td>\n",
              "      <td>4.854886</td>\n",
              "      <td>0.030155</td>\n",
              "      <td>3.829631</td>\n",
              "      <td>0.331700</td>\n",
              "      <td>99.992559</td>\n",
              "      <td>99.992559</td>\n",
              "      <td>99.992559</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>15</th>\n",
              "      <td>2.252528</td>\n",
              "      <td>254.940932</td>\n",
              "      <td>373.408279</td>\n",
              "      <td>509.748554</td>\n",
              "      <td>1.790289</td>\n",
              "      <td>0.037890</td>\n",
              "      <td>0.056835</td>\n",
              "      <td>0.018945</td>\n",
              "      <td>103.552598</td>\n",
              "      <td>103.552598</td>\n",
              "      <td>103.552598</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>16</th>\n",
              "      <td>0.679950</td>\n",
              "      <td>0.640772</td>\n",
              "      <td>0.030418</td>\n",
              "      <td>2.761938</td>\n",
              "      <td>3.793790</td>\n",
              "      <td>0.031881</td>\n",
              "      <td>0.031881</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>99.913759</td>\n",
              "      <td>99.913759</td>\n",
              "      <td>99.913759</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>17</th>\n",
              "      <td>0.221427</td>\n",
              "      <td>0.228784</td>\n",
              "      <td>4.152347</td>\n",
              "      <td>2.779503</td>\n",
              "      <td>5.647729</td>\n",
              "      <td>0.030364</td>\n",
              "      <td>3.643696</td>\n",
              "      <td>0.030364</td>\n",
              "      <td>99.897995</td>\n",
              "      <td>99.897995</td>\n",
              "      <td>99.897995</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>18</th>\n",
              "      <td>2.491634</td>\n",
              "      <td>1.417418</td>\n",
              "      <td>0.355384</td>\n",
              "      <td>5.589534</td>\n",
              "      <td>1.621276</td>\n",
              "      <td>3.170496</td>\n",
              "      <td>7.926240</td>\n",
              "      <td>0.756596</td>\n",
              "      <td>99.996725</td>\n",
              "      <td>99.996725</td>\n",
              "      <td>99.996725</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>19</th>\n",
              "      <td>2.343851</td>\n",
              "      <td>5.380558</td>\n",
              "      <td>0.973954</td>\n",
              "      <td>5.547942</td>\n",
              "      <td>1.636000</td>\n",
              "      <td>4.024559</td>\n",
              "      <td>1.636000</td>\n",
              "      <td>0.752560</td>\n",
              "      <td>100.008663</td>\n",
              "      <td>100.008663</td>\n",
              "      <td>100.008663</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "        Ampl    Moving_x    Moving_y  ...  mean_freq_y  mean_freq_z  answer\n",
              "0   0.062103    0.152437    0.468787  ...   125.003590   125.003590     0.0\n",
              "1   0.200008    0.081242    0.509455  ...   125.009549   125.009549     0.0\n",
              "2   0.181625    0.103494    1.133002  ...   124.992891   124.992891     0.0\n",
              "3   0.069663    2.406644    0.770164  ...   125.001594   125.001594     0.0\n",
              "4   0.399522   32.343050    2.207324  ...   124.998667   124.998667     0.0\n",
              "5   1.449805    0.801564   23.829840  ...   125.011831   125.011831     1.0\n",
              "6   1.738185    1.522133   23.404211  ...   125.005967   125.005967     1.0\n",
              "7   2.703319   14.396613    0.989242  ...   125.011465   125.011465     1.0\n",
              "8   1.474270   13.022342   49.106109  ...   125.000438   125.000438     1.0\n",
              "9   3.496564    2.614811    0.271458  ...    99.993186    99.993186     3.0\n",
              "10  0.881452    0.096376    0.012329  ...    99.704311    99.704311     3.0\n",
              "11  3.656799    5.928100    7.905616  ...    99.984625    99.984625     1.0\n",
              "12  3.829502    3.287389    0.757327  ...    99.980087    99.980087     1.0\n",
              "13  5.722513    1.970641    0.861193  ...    99.987938    99.987938     4.0\n",
              "14  0.024133    0.935009    0.224295  ...    99.992559    99.992559     0.0\n",
              "15  2.252528  254.940932  373.408279  ...   103.552598   103.552598     0.0\n",
              "16  0.679950    0.640772    0.030418  ...    99.913759    99.913759     0.0\n",
              "17  0.221427    0.228784    4.152347  ...    99.897995    99.897995     0.0\n",
              "18  2.491634    1.417418    0.355384  ...    99.996725    99.996725     1.0\n",
              "19  2.343851    5.380558    0.973954  ...   100.008663   100.008663     1.0\n",
              "\n",
              "[20 rows x 12 columns]"
            ]
          },
          "metadata": {},
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "w_8i7DLXMmaq"
      },
      "source": [
        "Напишем функцию для получения предсказания (здесь используется только амплитуда, но в вашем итоговом решении будет больше признаков)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "b9znacDpMmaq"
      },
      "source": [
        "features = 8\n",
        "classes = 8"
      ],
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5_bfMujPMmaq",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "17f82a6d-74e8-418f-c2ee-bd3ea8d4dd72"
      },
      "source": [
        "!pip install torch"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: torch in /usr/local/lib/python3.7/dist-packages (1.9.0+cu102)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from torch) (3.7.4.3)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GBs6BbvRMmaq",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "080baad8-f956-40a1-9fa3-aad08a5d337e"
      },
      "source": [
        "!pip install torchvision"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: torchvision in /usr/local/lib/python3.7/dist-packages (0.10.0+cu102)\n",
            "Requirement already satisfied: torch==1.9.0 in /usr/local/lib/python3.7/dist-packages (from torchvision) (1.9.0+cu102)\n",
            "Requirement already satisfied: pillow>=5.3.0 in /usr/local/lib/python3.7/dist-packages (from torchvision) (7.1.2)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from torchvision) (1.19.5)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from torch==1.9.0->torchvision) (3.7.4.3)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sVU0V7BAMmar"
      },
      "source": [
        "import torch\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split\n",
        "import torch.nn as nn\n",
        "from torchvision.datasets import MNIST\n",
        "import torchvision.transforms as tfs\n",
        "import torch.utils.data as data_utils"
      ],
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qdXHkrXHMmar",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "564313ba-304f-48f0-aad1-bb3460234442"
      },
      "source": [
        "!pip install catboost"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: catboost in /usr/local/lib/python3.7/dist-packages (0.26.1)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.7/dist-packages (from catboost) (3.2.2)\n",
            "Requirement already satisfied: numpy>=1.16.0 in /usr/local/lib/python3.7/dist-packages (from catboost) (1.19.5)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from catboost) (1.15.0)\n",
            "Requirement already satisfied: pandas>=0.24.0 in /usr/local/lib/python3.7/dist-packages (from catboost) (1.1.5)\n",
            "Requirement already satisfied: graphviz in /usr/local/lib/python3.7/dist-packages (from catboost) (0.10.1)\n",
            "Requirement already satisfied: plotly in /usr/local/lib/python3.7/dist-packages (from catboost) (4.4.1)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.7/dist-packages (from catboost) (1.4.1)\n",
            "Requirement already satisfied: python-dateutil>=2.7.3 in /usr/local/lib/python3.7/dist-packages (from pandas>=0.24.0->catboost) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2017.2 in /usr/local/lib/python3.7/dist-packages (from pandas>=0.24.0->catboost) (2018.9)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.7/dist-packages (from matplotlib->catboost) (0.10.0)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib->catboost) (1.3.1)\n",
            "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib->catboost) (2.4.7)\n",
            "Requirement already satisfied: retrying>=1.3.3 in /usr/local/lib/python3.7/dist-packages (from plotly->catboost) (1.3.3)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Duilh1eQMmar"
      },
      "source": [
        "import catboost"
      ],
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3a9xz7emMmar",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0488fc6e-5496-43b6-b129-4c5207446901"
      },
      "source": [
        "X = Data_train.drop(columns=['answer'])\n",
        "y = Data_train['answer']\n",
        "X_train_origin, X_test_origin, y_train, y_test = train_test_split(X, y, \n",
        "                                                       train_size=0.8, \n",
        "                                                       random_state=42)\n",
        "boosting_model = catboost.CatBoostClassifier(n_estimators=200, \n",
        "                                             cat_features=[],task_type='GPU')\n",
        "\n",
        "boosting_model.grid_search({'l2_leaf_reg': np.linspace(0, 5, 4), 'learning_rate': [0.03, 0.1, 0.05],'depth': [4, 6, 8]}, \n",
        "                           X_train_origin, \n",
        "                           y_train, refit=True)"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0:\tlearn: 1.8215096\ttest: 1.8298033\tbest: 1.8298033 (0)\n",
            "1:\tlearn: 1.6580849\ttest: 1.6761590\tbest: 1.6761590 (1)\n",
            "2:\tlearn: 1.5255840\ttest: 1.5512514\tbest: 1.5512514 (2)\n",
            "3:\tlearn: 1.4115721\ttest: 1.4436825\tbest: 1.4436825 (3)\n",
            "4:\tlearn: 1.3279609\ttest: 1.3645241\tbest: 1.3645241 (4)\n",
            "5:\tlearn: 1.2549274\ttest: 1.2984185\tbest: 1.2984185 (5)\n",
            "6:\tlearn: 1.1913727\ttest: 1.2382476\tbest: 1.2382476 (6)\n",
            "7:\tlearn: 1.1348701\ttest: 1.1872658\tbest: 1.1872658 (7)\n",
            "8:\tlearn: 1.0861901\ttest: 1.1423481\tbest: 1.1423481 (8)\n",
            "9:\tlearn: 1.0406621\ttest: 1.1037902\tbest: 1.1037902 (9)\n",
            "10:\tlearn: 1.0054537\ttest: 1.0717628\tbest: 1.0717628 (10)\n",
            "11:\tlearn: 0.9734954\ttest: 1.0449383\tbest: 1.0449383 (11)\n",
            "12:\tlearn: 0.9419461\ttest: 1.0173201\tbest: 1.0173201 (12)\n",
            "13:\tlearn: 0.9121638\ttest: 0.9915801\tbest: 0.9915801 (13)\n",
            "14:\tlearn: 0.8890932\ttest: 0.9723627\tbest: 0.9723627 (14)\n",
            "15:\tlearn: 0.8609764\ttest: 0.9502892\tbest: 0.9502892 (15)\n",
            "16:\tlearn: 0.8375755\ttest: 0.9304215\tbest: 0.9304215 (16)\n",
            "17:\tlearn: 0.8194186\ttest: 0.9165385\tbest: 0.9165385 (17)\n",
            "18:\tlearn: 0.8001942\ttest: 0.8982460\tbest: 0.8982460 (18)\n",
            "19:\tlearn: 0.7825609\ttest: 0.8843842\tbest: 0.8843842 (19)\n",
            "20:\tlearn: 0.7638424\ttest: 0.8677627\tbest: 0.8677627 (20)\n",
            "21:\tlearn: 0.7475569\ttest: 0.8544135\tbest: 0.8544135 (21)\n",
            "22:\tlearn: 0.7327649\ttest: 0.8449585\tbest: 0.8449585 (22)\n",
            "23:\tlearn: 0.7207610\ttest: 0.8363312\tbest: 0.8363312 (23)\n",
            "24:\tlearn: 0.7078825\ttest: 0.8273811\tbest: 0.8273811 (24)\n",
            "25:\tlearn: 0.6964719\ttest: 0.8182247\tbest: 0.8182247 (25)\n",
            "26:\tlearn: 0.6847411\ttest: 0.8099265\tbest: 0.8099265 (26)\n",
            "27:\tlearn: 0.6747712\ttest: 0.8027818\tbest: 0.8027818 (27)\n",
            "28:\tlearn: 0.6632518\ttest: 0.7955020\tbest: 0.7955020 (28)\n",
            "29:\tlearn: 0.6545399\ttest: 0.7893571\tbest: 0.7893571 (29)\n",
            "30:\tlearn: 0.6428620\ttest: 0.7813502\tbest: 0.7813502 (30)\n",
            "31:\tlearn: 0.6335189\ttest: 0.7761548\tbest: 0.7761548 (31)\n",
            "32:\tlearn: 0.6259938\ttest: 0.7708092\tbest: 0.7708092 (32)\n",
            "33:\tlearn: 0.6168173\ttest: 0.7660297\tbest: 0.7660297 (33)\n",
            "34:\tlearn: 0.6104155\ttest: 0.7615516\tbest: 0.7615516 (34)\n",
            "35:\tlearn: 0.6030588\ttest: 0.7569373\tbest: 0.7569373 (35)\n",
            "36:\tlearn: 0.5956623\ttest: 0.7522240\tbest: 0.7522240 (36)\n",
            "37:\tlearn: 0.5886675\ttest: 0.7479235\tbest: 0.7479235 (37)\n",
            "38:\tlearn: 0.5825854\ttest: 0.7433773\tbest: 0.7433773 (38)\n",
            "39:\tlearn: 0.5759663\ttest: 0.7399593\tbest: 0.7399593 (39)\n",
            "40:\tlearn: 0.5693440\ttest: 0.7360656\tbest: 0.7360656 (40)\n",
            "41:\tlearn: 0.5628883\ttest: 0.7326894\tbest: 0.7326894 (41)\n",
            "42:\tlearn: 0.5578434\ttest: 0.7299680\tbest: 0.7299680 (42)\n",
            "43:\tlearn: 0.5514047\ttest: 0.7265054\tbest: 0.7265054 (43)\n",
            "44:\tlearn: 0.5475190\ttest: 0.7246526\tbest: 0.7246526 (44)\n",
            "45:\tlearn: 0.5407604\ttest: 0.7194268\tbest: 0.7194268 (45)\n",
            "46:\tlearn: 0.5355605\ttest: 0.7169302\tbest: 0.7169302 (46)\n",
            "47:\tlearn: 0.5309080\ttest: 0.7149484\tbest: 0.7149484 (47)\n",
            "48:\tlearn: 0.5261653\ttest: 0.7119875\tbest: 0.7119875 (48)\n",
            "49:\tlearn: 0.5206564\ttest: 0.7086571\tbest: 0.7086571 (49)\n",
            "50:\tlearn: 0.5170081\ttest: 0.7057493\tbest: 0.7057493 (50)\n",
            "51:\tlearn: 0.5133661\ttest: 0.7032358\tbest: 0.7032358 (51)\ttotal: 4.15s\tremaining: 11.8s\n",
            "52:\tlearn: 0.5075428\ttest: 0.7007521\tbest: 0.7007521 (52)\n",
            "53:\tlearn: 0.5034261\ttest: 0.6994512\tbest: 0.6994512 (53)\n",
            "54:\tlearn: 0.4979604\ttest: 0.6979358\tbest: 0.6979358 (54)\n",
            "55:\tlearn: 0.4939959\ttest: 0.6957114\tbest: 0.6957114 (55)\n",
            "56:\tlearn: 0.4899643\ttest: 0.6931928\tbest: 0.6931928 (56)\n",
            "57:\tlearn: 0.4864081\ttest: 0.6921024\tbest: 0.6921024 (57)\n",
            "58:\tlearn: 0.4828950\ttest: 0.6896364\tbest: 0.6896364 (58)\n",
            "59:\tlearn: 0.4798501\ttest: 0.6885686\tbest: 0.6885686 (59)\n",
            "60:\tlearn: 0.4760871\ttest: 0.6857649\tbest: 0.6857649 (60)\n",
            "61:\tlearn: 0.4730703\ttest: 0.6842280\tbest: 0.6842280 (61)\n",
            "62:\tlearn: 0.4699805\ttest: 0.6823551\tbest: 0.6823551 (62)\n",
            "63:\tlearn: 0.4668430\ttest: 0.6810546\tbest: 0.6810546 (63)\n",
            "64:\tlearn: 0.4624265\ttest: 0.6782153\tbest: 0.6782153 (64)\n",
            "65:\tlearn: 0.4592230\ttest: 0.6765539\tbest: 0.6765539 (65)\n",
            "66:\tlearn: 0.4572814\ttest: 0.6750249\tbest: 0.6750249 (66)\n",
            "67:\tlearn: 0.4533049\ttest: 0.6738503\tbest: 0.6738503 (67)\n",
            "68:\tlearn: 0.4506708\ttest: 0.6724466\tbest: 0.6724466 (68)\n",
            "69:\tlearn: 0.4469851\ttest: 0.6707868\tbest: 0.6707868 (69)\n",
            "70:\tlearn: 0.4436375\ttest: 0.6682853\tbest: 0.6682853 (70)\n",
            "71:\tlearn: 0.4412072\ttest: 0.6676881\tbest: 0.6676881 (71)\n",
            "72:\tlearn: 0.4385680\ttest: 0.6664393\tbest: 0.6664393 (72)\n",
            "73:\tlearn: 0.4354643\ttest: 0.6660898\tbest: 0.6660898 (73)\n",
            "74:\tlearn: 0.4321271\ttest: 0.6647873\tbest: 0.6647873 (74)\n",
            "75:\tlearn: 0.4299953\ttest: 0.6638867\tbest: 0.6638867 (75)\n",
            "76:\tlearn: 0.4276524\ttest: 0.6627825\tbest: 0.6627825 (76)\n",
            "77:\tlearn: 0.4244592\ttest: 0.6616288\tbest: 0.6616288 (77)\n",
            "78:\tlearn: 0.4214416\ttest: 0.6609940\tbest: 0.6609940 (78)\n",
            "79:\tlearn: 0.4181688\ttest: 0.6592029\tbest: 0.6592029 (79)\n",
            "80:\tlearn: 0.4160883\ttest: 0.6579201\tbest: 0.6579201 (80)\n",
            "81:\tlearn: 0.4130637\ttest: 0.6568096\tbest: 0.6568096 (81)\n",
            "82:\tlearn: 0.4105031\ttest: 0.6561293\tbest: 0.6561293 (82)\n",
            "83:\tlearn: 0.4080919\ttest: 0.6553205\tbest: 0.6553205 (83)\n",
            "84:\tlearn: 0.4055657\ttest: 0.6542130\tbest: 0.6542130 (84)\n",
            "85:\tlearn: 0.4030629\ttest: 0.6533864\tbest: 0.6533864 (85)\n",
            "86:\tlearn: 0.3997620\ttest: 0.6525087\tbest: 0.6525087 (86)\n",
            "87:\tlearn: 0.3975006\ttest: 0.6512537\tbest: 0.6512537 (87)\n",
            "88:\tlearn: 0.3949521\ttest: 0.6508907\tbest: 0.6508907 (88)\n",
            "89:\tlearn: 0.3918401\ttest: 0.6499379\tbest: 0.6499379 (89)\n",
            "90:\tlearn: 0.3890465\ttest: 0.6482128\tbest: 0.6482128 (90)\n",
            "91:\tlearn: 0.3869760\ttest: 0.6480038\tbest: 0.6480038 (91)\n",
            "92:\tlearn: 0.3850146\ttest: 0.6478326\tbest: 0.6478326 (92)\n",
            "93:\tlearn: 0.3828331\ttest: 0.6472935\tbest: 0.6472935 (93)\n",
            "94:\tlearn: 0.3806668\ttest: 0.6463583\tbest: 0.6463583 (94)\n",
            "95:\tlearn: 0.3779257\ttest: 0.6461548\tbest: 0.6461548 (95)\n",
            "96:\tlearn: 0.3760568\ttest: 0.6456379\tbest: 0.6456379 (96)\n",
            "97:\tlearn: 0.3736297\ttest: 0.6442834\tbest: 0.6442834 (97)\n",
            "98:\tlearn: 0.3715139\ttest: 0.6439368\tbest: 0.6439368 (98)\n",
            "99:\tlearn: 0.3687353\ttest: 0.6430055\tbest: 0.6430055 (99)\n",
            "100:\tlearn: 0.3668277\ttest: 0.6420527\tbest: 0.6420527 (100)\n",
            "101:\tlearn: 0.3650268\ttest: 0.6406046\tbest: 0.6406046 (101)\n",
            "102:\tlearn: 0.3633285\ttest: 0.6395017\tbest: 0.6395017 (102)\ttotal: 8.37s\tremaining: 7.88s\n",
            "103:\tlearn: 0.3610532\ttest: 0.6391905\tbest: 0.6391905 (103)\n",
            "104:\tlearn: 0.3589522\ttest: 0.6381518\tbest: 0.6381518 (104)\n",
            "105:\tlearn: 0.3561922\ttest: 0.6369114\tbest: 0.6369114 (105)\n",
            "106:\tlearn: 0.3540108\ttest: 0.6357345\tbest: 0.6357345 (106)\n",
            "107:\tlearn: 0.3518436\ttest: 0.6349047\tbest: 0.6349047 (107)\n",
            "108:\tlearn: 0.3497686\ttest: 0.6343363\tbest: 0.6343363 (108)\n",
            "109:\tlearn: 0.3480522\ttest: 0.6330625\tbest: 0.6330625 (109)\n",
            "110:\tlearn: 0.3467316\ttest: 0.6328964\tbest: 0.6328964 (110)\n",
            "111:\tlearn: 0.3446106\ttest: 0.6324278\tbest: 0.6324278 (111)\n",
            "112:\tlearn: 0.3430424\ttest: 0.6308851\tbest: 0.6308851 (112)\n",
            "113:\tlearn: 0.3416998\ttest: 0.6301479\tbest: 0.6301479 (113)\n",
            "114:\tlearn: 0.3390388\ttest: 0.6300919\tbest: 0.6300919 (114)\n",
            "115:\tlearn: 0.3369520\ttest: 0.6289768\tbest: 0.6289768 (115)\n",
            "116:\tlearn: 0.3355321\ttest: 0.6288341\tbest: 0.6288341 (116)\n",
            "117:\tlearn: 0.3338954\ttest: 0.6287581\tbest: 0.6287581 (117)\n",
            "118:\tlearn: 0.3319232\ttest: 0.6281997\tbest: 0.6281997 (118)\n",
            "119:\tlearn: 0.3305779\ttest: 0.6277279\tbest: 0.6277279 (119)\n",
            "120:\tlearn: 0.3285598\ttest: 0.6266102\tbest: 0.6266102 (120)\n",
            "121:\tlearn: 0.3272635\ttest: 0.6261855\tbest: 0.6261855 (121)\n",
            "122:\tlearn: 0.3258808\ttest: 0.6260962\tbest: 0.6260962 (122)\n",
            "123:\tlearn: 0.3245199\ttest: 0.6256688\tbest: 0.6256688 (123)\n",
            "124:\tlearn: 0.3231419\ttest: 0.6261181\tbest: 0.6256688 (123)\n",
            "125:\tlearn: 0.3218256\ttest: 0.6256196\tbest: 0.6256196 (125)\n",
            "126:\tlearn: 0.3205560\ttest: 0.6257073\tbest: 0.6256196 (125)\n",
            "127:\tlearn: 0.3191543\ttest: 0.6250078\tbest: 0.6250078 (127)\n",
            "128:\tlearn: 0.3173644\ttest: 0.6245685\tbest: 0.6245685 (128)\n",
            "129:\tlearn: 0.3156718\ttest: 0.6245188\tbest: 0.6245188 (129)\n",
            "130:\tlearn: 0.3136290\ttest: 0.6237204\tbest: 0.6237204 (130)\n",
            "131:\tlearn: 0.3123967\ttest: 0.6230389\tbest: 0.6230389 (131)\n",
            "132:\tlearn: 0.3110243\ttest: 0.6224179\tbest: 0.6224179 (132)\n",
            "133:\tlearn: 0.3091823\ttest: 0.6226166\tbest: 0.6224179 (132)\n",
            "134:\tlearn: 0.3075910\ttest: 0.6220049\tbest: 0.6220049 (134)\n",
            "135:\tlearn: 0.3061723\ttest: 0.6216006\tbest: 0.6216006 (135)\n",
            "136:\tlearn: 0.3047938\ttest: 0.6212371\tbest: 0.6212371 (136)\n",
            "137:\tlearn: 0.3031258\ttest: 0.6213810\tbest: 0.6212371 (136)\n",
            "138:\tlearn: 0.3015571\ttest: 0.6207833\tbest: 0.6207833 (138)\n",
            "139:\tlearn: 0.2998632\ttest: 0.6207377\tbest: 0.6207377 (139)\n",
            "140:\tlearn: 0.2980020\ttest: 0.6192517\tbest: 0.6192517 (140)\n",
            "141:\tlearn: 0.2959234\ttest: 0.6183755\tbest: 0.6183755 (141)\n",
            "142:\tlearn: 0.2945266\ttest: 0.6186020\tbest: 0.6183755 (141)\n",
            "143:\tlearn: 0.2934091\ttest: 0.6188689\tbest: 0.6183755 (141)\n",
            "144:\tlearn: 0.2921350\ttest: 0.6187249\tbest: 0.6183755 (141)\n",
            "145:\tlearn: 0.2903740\ttest: 0.6185319\tbest: 0.6183755 (141)\n",
            "146:\tlearn: 0.2883936\ttest: 0.6184581\tbest: 0.6183755 (141)\n",
            "147:\tlearn: 0.2870564\ttest: 0.6181235\tbest: 0.6181235 (147)\n",
            "148:\tlearn: 0.2856770\ttest: 0.6175152\tbest: 0.6175152 (148)\n",
            "149:\tlearn: 0.2848199\ttest: 0.6172270\tbest: 0.6172270 (149)\n",
            "150:\tlearn: 0.2836297\ttest: 0.6169453\tbest: 0.6169453 (150)\n",
            "151:\tlearn: 0.2821197\ttest: 0.6164572\tbest: 0.6164572 (151)\n",
            "152:\tlearn: 0.2808130\ttest: 0.6152220\tbest: 0.6152220 (152)\n",
            "153:\tlearn: 0.2798997\ttest: 0.6151692\tbest: 0.6151692 (153)\n",
            "154:\tlearn: 0.2787704\ttest: 0.6155202\tbest: 0.6151692 (153)\ttotal: 12.6s\tremaining: 3.67s\n",
            "155:\tlearn: 0.2772309\ttest: 0.6150831\tbest: 0.6150831 (155)\n",
            "156:\tlearn: 0.2762866\ttest: 0.6145738\tbest: 0.6145738 (156)\n",
            "157:\tlearn: 0.2749572\ttest: 0.6145598\tbest: 0.6145598 (157)\n",
            "158:\tlearn: 0.2737878\ttest: 0.6138462\tbest: 0.6138462 (158)\n",
            "159:\tlearn: 0.2727504\ttest: 0.6135110\tbest: 0.6135110 (159)\n",
            "160:\tlearn: 0.2716208\ttest: 0.6136506\tbest: 0.6135110 (159)\n",
            "161:\tlearn: 0.2705458\ttest: 0.6133005\tbest: 0.6133005 (161)\n",
            "162:\tlearn: 0.2696289\ttest: 0.6132616\tbest: 0.6132616 (162)\n",
            "163:\tlearn: 0.2684663\ttest: 0.6131574\tbest: 0.6131574 (163)\n",
            "164:\tlearn: 0.2673042\ttest: 0.6122001\tbest: 0.6122001 (164)\n",
            "165:\tlearn: 0.2662613\ttest: 0.6120133\tbest: 0.6120133 (165)\n",
            "166:\tlearn: 0.2648036\ttest: 0.6114704\tbest: 0.6114704 (166)\n",
            "167:\tlearn: 0.2630606\ttest: 0.6110116\tbest: 0.6110116 (167)\n",
            "168:\tlearn: 0.2623920\ttest: 0.6111738\tbest: 0.6110116 (167)\n",
            "169:\tlearn: 0.2613221\ttest: 0.6111706\tbest: 0.6110116 (167)\n",
            "170:\tlearn: 0.2600506\ttest: 0.6109235\tbest: 0.6109235 (170)\n",
            "171:\tlearn: 0.2592917\ttest: 0.6109358\tbest: 0.6109235 (170)\n",
            "172:\tlearn: 0.2579329\ttest: 0.6107962\tbest: 0.6107962 (172)\n",
            "173:\tlearn: 0.2570810\ttest: 0.6106295\tbest: 0.6106295 (173)\n",
            "174:\tlearn: 0.2562430\ttest: 0.6106459\tbest: 0.6106295 (173)\n",
            "175:\tlearn: 0.2551992\ttest: 0.6102603\tbest: 0.6102603 (175)\n",
            "176:\tlearn: 0.2542050\ttest: 0.6104886\tbest: 0.6102603 (175)\n",
            "177:\tlearn: 0.2535404\ttest: 0.6100939\tbest: 0.6100939 (177)\n",
            "178:\tlearn: 0.2526945\ttest: 0.6096251\tbest: 0.6096251 (178)\n",
            "179:\tlearn: 0.2518887\ttest: 0.6093136\tbest: 0.6093136 (179)\n",
            "180:\tlearn: 0.2507135\ttest: 0.6089998\tbest: 0.6089998 (180)\n",
            "181:\tlearn: 0.2498109\ttest: 0.6089998\tbest: 0.6089998 (181)\n",
            "182:\tlearn: 0.2482466\ttest: 0.6082957\tbest: 0.6082957 (182)\n",
            "183:\tlearn: 0.2473123\ttest: 0.6080489\tbest: 0.6080489 (183)\n",
            "184:\tlearn: 0.2463524\ttest: 0.6077335\tbest: 0.6077335 (184)\n",
            "185:\tlearn: 0.2455210\ttest: 0.6081037\tbest: 0.6077335 (184)\n",
            "186:\tlearn: 0.2442177\ttest: 0.6081648\tbest: 0.6077335 (184)\n",
            "187:\tlearn: 0.2429480\ttest: 0.6078604\tbest: 0.6077335 (184)\n",
            "188:\tlearn: 0.2418452\ttest: 0.6076662\tbest: 0.6076662 (188)\n",
            "189:\tlearn: 0.2407489\ttest: 0.6080658\tbest: 0.6076662 (188)\n",
            "190:\tlearn: 0.2399253\ttest: 0.6078189\tbest: 0.6076662 (188)\n",
            "191:\tlearn: 0.2387865\ttest: 0.6080319\tbest: 0.6076662 (188)\n",
            "192:\tlearn: 0.2375571\ttest: 0.6071747\tbest: 0.6071747 (192)\n",
            "193:\tlearn: 0.2364811\ttest: 0.6064482\tbest: 0.6064482 (193)\n",
            "194:\tlearn: 0.2356449\ttest: 0.6067663\tbest: 0.6064482 (193)\n",
            "195:\tlearn: 0.2346519\ttest: 0.6071032\tbest: 0.6064482 (193)\n",
            "196:\tlearn: 0.2336071\ttest: 0.6074003\tbest: 0.6064482 (193)\n",
            "197:\tlearn: 0.2325133\ttest: 0.6075335\tbest: 0.6064482 (193)\n",
            "198:\tlearn: 0.2310267\ttest: 0.6075155\tbest: 0.6064482 (193)\ttotal: 16.8s\tremaining: 84.5ms\n",
            "199:\tlearn: 0.2299505\ttest: 0.6075155\tbest: 0.6064482 (193)\ttotal: 20.2s\tremaining: 0us\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'cv_results': defaultdict(list,\n",
              "             {'iterations': [0,\n",
              "               1,\n",
              "               2,\n",
              "               3,\n",
              "               4,\n",
              "               5,\n",
              "               6,\n",
              "               7,\n",
              "               8,\n",
              "               9,\n",
              "               10,\n",
              "               11,\n",
              "               12,\n",
              "               13,\n",
              "               14,\n",
              "               15,\n",
              "               16,\n",
              "               17,\n",
              "               18,\n",
              "               19,\n",
              "               20,\n",
              "               21,\n",
              "               22,\n",
              "               23,\n",
              "               24,\n",
              "               25,\n",
              "               26,\n",
              "               27,\n",
              "               28,\n",
              "               29,\n",
              "               30,\n",
              "               31,\n",
              "               32,\n",
              "               33,\n",
              "               34,\n",
              "               35,\n",
              "               36,\n",
              "               37,\n",
              "               38,\n",
              "               39,\n",
              "               40,\n",
              "               41,\n",
              "               42,\n",
              "               43,\n",
              "               44,\n",
              "               45,\n",
              "               46,\n",
              "               47,\n",
              "               48,\n",
              "               49,\n",
              "               50,\n",
              "               51,\n",
              "               52,\n",
              "               53,\n",
              "               54,\n",
              "               55,\n",
              "               56,\n",
              "               57,\n",
              "               58,\n",
              "               59,\n",
              "               60,\n",
              "               61,\n",
              "               62,\n",
              "               63,\n",
              "               64,\n",
              "               65,\n",
              "               66,\n",
              "               67,\n",
              "               68,\n",
              "               69,\n",
              "               70,\n",
              "               71,\n",
              "               72,\n",
              "               73,\n",
              "               74,\n",
              "               75,\n",
              "               76,\n",
              "               77,\n",
              "               78,\n",
              "               79,\n",
              "               80,\n",
              "               81,\n",
              "               82,\n",
              "               83,\n",
              "               84,\n",
              "               85,\n",
              "               86,\n",
              "               87,\n",
              "               88,\n",
              "               89,\n",
              "               90,\n",
              "               91,\n",
              "               92,\n",
              "               93,\n",
              "               94,\n",
              "               95,\n",
              "               96,\n",
              "               97,\n",
              "               98,\n",
              "               99,\n",
              "               100,\n",
              "               101,\n",
              "               102,\n",
              "               103,\n",
              "               104,\n",
              "               105,\n",
              "               106,\n",
              "               107,\n",
              "               108,\n",
              "               109,\n",
              "               110,\n",
              "               111,\n",
              "               112,\n",
              "               113,\n",
              "               114,\n",
              "               115,\n",
              "               116,\n",
              "               117,\n",
              "               118,\n",
              "               119,\n",
              "               120,\n",
              "               121,\n",
              "               122,\n",
              "               123,\n",
              "               124,\n",
              "               125,\n",
              "               126,\n",
              "               127,\n",
              "               128,\n",
              "               129,\n",
              "               130,\n",
              "               131,\n",
              "               132,\n",
              "               133,\n",
              "               134,\n",
              "               135,\n",
              "               136,\n",
              "               137,\n",
              "               138,\n",
              "               139,\n",
              "               140,\n",
              "               141,\n",
              "               142,\n",
              "               143,\n",
              "               144,\n",
              "               145,\n",
              "               146,\n",
              "               147,\n",
              "               148,\n",
              "               149,\n",
              "               150,\n",
              "               151,\n",
              "               152,\n",
              "               153,\n",
              "               154,\n",
              "               155,\n",
              "               156,\n",
              "               157,\n",
              "               158,\n",
              "               159,\n",
              "               160,\n",
              "               161,\n",
              "               162,\n",
              "               163,\n",
              "               164,\n",
              "               165,\n",
              "               166,\n",
              "               167,\n",
              "               168,\n",
              "               169,\n",
              "               170,\n",
              "               171,\n",
              "               172,\n",
              "               173,\n",
              "               174,\n",
              "               175,\n",
              "               176,\n",
              "               177,\n",
              "               178,\n",
              "               179,\n",
              "               180,\n",
              "               181,\n",
              "               182,\n",
              "               183,\n",
              "               184,\n",
              "               185,\n",
              "               186,\n",
              "               187,\n",
              "               188,\n",
              "               189,\n",
              "               190,\n",
              "               191,\n",
              "               192,\n",
              "               193,\n",
              "               194,\n",
              "               195,\n",
              "               196,\n",
              "               197,\n",
              "               198,\n",
              "               199],\n",
              "              'test-MultiClass-mean': [1.8298032626443634,\n",
              "               1.6761589943489057,\n",
              "               1.5512513924120936,\n",
              "               1.4436825249212173,\n",
              "               1.3645241499729843,\n",
              "               1.2984185452231465,\n",
              "               1.2382475646278868,\n",
              "               1.1872658335860242,\n",
              "               1.1423480804019734,\n",
              "               1.1037901901724998,\n",
              "               1.0717628001178907,\n",
              "               1.0449383263333798,\n",
              "               1.0173201022776308,\n",
              "               0.9915800751436881,\n",
              "               0.9723627481152768,\n",
              "               0.9502892212278585,\n",
              "               0.9304215012775852,\n",
              "               0.9165384542414845,\n",
              "               0.8982459533850374,\n",
              "               0.8843842332256449,\n",
              "               0.8677626902950246,\n",
              "               0.8544135065539544,\n",
              "               0.8449584786735879,\n",
              "               0.8363311600708879,\n",
              "               0.8273811135970911,\n",
              "               0.8182247456436323,\n",
              "               0.8099264617048968,\n",
              "               0.8027817840484474,\n",
              "               0.7955020149752393,\n",
              "               0.789357145087301,\n",
              "               0.7813501820785241,\n",
              "               0.7761547776346175,\n",
              "               0.770809249652943,\n",
              "               0.7660296674944173,\n",
              "               0.7615516236995861,\n",
              "               0.756937298781646,\n",
              "               0.752223954321796,\n",
              "               0.7479235082471488,\n",
              "               0.7433772808858473,\n",
              "               0.7399593185032965,\n",
              "               0.7360656344445685,\n",
              "               0.73268942918751,\n",
              "               0.7299680130535698,\n",
              "               0.7265053586174909,\n",
              "               0.7246526470013966,\n",
              "               0.7194267951331557,\n",
              "               0.7169302270529841,\n",
              "               0.7149483705013037,\n",
              "               0.7119875299494415,\n",
              "               0.7086570644030186,\n",
              "               0.7057493131995626,\n",
              "               0.7032358373482923,\n",
              "               0.7007520905207588,\n",
              "               0.6994512277758599,\n",
              "               0.6979358254229308,\n",
              "               0.6957114323330206,\n",
              "               0.6931927596125952,\n",
              "               0.6921024463327329,\n",
              "               0.6896363820145733,\n",
              "               0.6885686413145716,\n",
              "               0.6857648983634936,\n",
              "               0.6842280031256767,\n",
              "               0.6823551200341816,\n",
              "               0.6810546248463595,\n",
              "               0.6782153437596777,\n",
              "               0.6765538701667296,\n",
              "               0.6750248574510761,\n",
              "               0.6738502848576585,\n",
              "               0.6724466356330036,\n",
              "               0.6707868274888676,\n",
              "               0.6682852889315205,\n",
              "               0.667688088049494,\n",
              "               0.6664392636244214,\n",
              "               0.6660898122614769,\n",
              "               0.6647873262875139,\n",
              "               0.6638867404566725,\n",
              "               0.6627824895957276,\n",
              "               0.6616287659244157,\n",
              "               0.6609940100649684,\n",
              "               0.6592028790326726,\n",
              "               0.6579201204886385,\n",
              "               0.6568095663119345,\n",
              "               0.6561293055261167,\n",
              "               0.6553205207788103,\n",
              "               0.654212990873275,\n",
              "               0.6533864248487848,\n",
              "               0.652508721152771,\n",
              "               0.6512537004246771,\n",
              "               0.650890685553421,\n",
              "               0.6499378972915818,\n",
              "               0.6482127757000432,\n",
              "               0.6480038415768847,\n",
              "               0.6478325817331595,\n",
              "               0.6472934895728302,\n",
              "               0.6463583225479805,\n",
              "               0.6461547524250933,\n",
              "               0.6456378930555919,\n",
              "               0.6442833841881979,\n",
              "               0.6439367584955663,\n",
              "               0.6430055089903473,\n",
              "               0.6420526972666815,\n",
              "               0.6406046436004884,\n",
              "               0.6395016911124106,\n",
              "               0.6391904974170265,\n",
              "               0.6381518285104631,\n",
              "               0.6369113868433457,\n",
              "               0.6357344789939293,\n",
              "               0.6349046918461777,\n",
              "               0.6343363346772108,\n",
              "               0.6330624970715237,\n",
              "               0.63289642151829,\n",
              "               0.632427845507574,\n",
              "               0.6308851312352153,\n",
              "               0.6301478699621255,\n",
              "               0.6300918685527532,\n",
              "               0.6289767723191062,\n",
              "               0.6288340752732355,\n",
              "               0.6287581104424015,\n",
              "               0.6281996700415987,\n",
              "               0.6277278600182638,\n",
              "               0.6266102104277268,\n",
              "               0.6261854717587709,\n",
              "               0.6260961638205391,\n",
              "               0.6256688416360819,\n",
              "               0.6261180969107222,\n",
              "               0.6256195767314087,\n",
              "               0.6257073001290662,\n",
              "               0.6250078063222694,\n",
              "               0.6245685049934232,\n",
              "               0.6245187782156632,\n",
              "               0.623720397600709,\n",
              "               0.6230389376137356,\n",
              "               0.6224179145534824,\n",
              "               0.6226166461269178,\n",
              "               0.6220049478182885,\n",
              "               0.6216006286720764,\n",
              "               0.621237136935422,\n",
              "               0.621381048636362,\n",
              "               0.6207833061660756,\n",
              "               0.6207376736998667,\n",
              "               0.6192516783932778,\n",
              "               0.6183754972819275,\n",
              "               0.618602046714924,\n",
              "               0.6188688564648016,\n",
              "               0.6187249016937003,\n",
              "               0.6185319167879877,\n",
              "               0.6184580632836437,\n",
              "               0.6181234664251174,\n",
              "               0.6175152110920479,\n",
              "               0.6172269733159621,\n",
              "               0.616945333272709,\n",
              "               0.6164571756549062,\n",
              "               0.6152219834858244,\n",
              "               0.6151691940706397,\n",
              "               0.6155202344721183,\n",
              "               0.6150830591744597,\n",
              "               0.6145738255155477,\n",
              "               0.6145597822106632,\n",
              "               0.6138461506134215,\n",
              "               0.6135110353133296,\n",
              "               0.6136506441614341,\n",
              "               0.6133004820897848,\n",
              "               0.6132615656934942,\n",
              "               0.6131574427125179,\n",
              "               0.6122000909381037,\n",
              "               0.612013334612956,\n",
              "               0.6114703522314484,\n",
              "               0.6110116408766556,\n",
              "               0.6111737513900736,\n",
              "               0.6111706374171426,\n",
              "               0.6109234953685144,\n",
              "               0.610935790072252,\n",
              "               0.6107962252592353,\n",
              "               0.6106294913234728,\n",
              "               0.6106459303711286,\n",
              "               0.6102603042954361,\n",
              "               0.6104885952679516,\n",
              "               0.6100938965678327,\n",
              "               0.609625132523404,\n",
              "               0.6093136459031645,\n",
              "               0.6089998465664362,\n",
              "               0.6089997694912732,\n",
              "               0.6082957092886624,\n",
              "               0.6080488870008515,\n",
              "               0.6077335328241086,\n",
              "               0.6081037296560856,\n",
              "               0.6081647618172465,\n",
              "               0.607860438937751,\n",
              "               0.6076662087771726,\n",
              "               0.6080658146270647,\n",
              "               0.6078189297956876,\n",
              "               0.6080318786093198,\n",
              "               0.607174730412559,\n",
              "               0.6064481692183964,\n",
              "               0.6067663232796355,\n",
              "               0.6071032155454507,\n",
              "               0.607400349576586,\n",
              "               0.6075335187516003,\n",
              "               0.6075155038690128,\n",
              "               0.6075155157144388],\n",
              "              'test-MultiClass-std': [0.008819184509553856,\n",
              "               0.006659669433412374,\n",
              "               0.0081743292449376,\n",
              "               0.014412488279816518,\n",
              "               0.014527331588327273,\n",
              "               0.013204994551897461,\n",
              "               0.013694763858280912,\n",
              "               0.01362791535093315,\n",
              "               0.014108360773033582,\n",
              "               0.011068731803904882,\n",
              "               0.012865899756724109,\n",
              "               0.014288472825027305,\n",
              "               0.012015352559653924,\n",
              "               0.01344992413336931,\n",
              "               0.015178311490121813,\n",
              "               0.014256365271277839,\n",
              "               0.01499717196116216,\n",
              "               0.018632765686531435,\n",
              "               0.018363916093471568,\n",
              "               0.014561092316280453,\n",
              "               0.015824477660970136,\n",
              "               0.01704356029598126,\n",
              "               0.0167211072043566,\n",
              "               0.018190123906384324,\n",
              "               0.01831300933443101,\n",
              "               0.01697678882417925,\n",
              "               0.01518310590690754,\n",
              "               0.016872488148100526,\n",
              "               0.016498787344726068,\n",
              "               0.017804050048304418,\n",
              "               0.017431014385395262,\n",
              "               0.016991495840999717,\n",
              "               0.0188781938222842,\n",
              "               0.01947039931297514,\n",
              "               0.02140898244638973,\n",
              "               0.02172429791078515,\n",
              "               0.023314959339224152,\n",
              "               0.023220016107764616,\n",
              "               0.022096097041189977,\n",
              "               0.020426730782337386,\n",
              "               0.021814950350768792,\n",
              "               0.02422315589767916,\n",
              "               0.024986856471288475,\n",
              "               0.026092246924947063,\n",
              "               0.027069833005254132,\n",
              "               0.025418709924738513,\n",
              "               0.025423861025019503,\n",
              "               0.02549823072096816,\n",
              "               0.025508257332773232,\n",
              "               0.027527820318656235,\n",
              "               0.028556247580539002,\n",
              "               0.029755410947465515,\n",
              "               0.029780223826822067,\n",
              "               0.028699226913038948,\n",
              "               0.029357822486548165,\n",
              "               0.030730891299949877,\n",
              "               0.031021532900750846,\n",
              "               0.03135243765274003,\n",
              "               0.03125344327134937,\n",
              "               0.0310044009664075,\n",
              "               0.030767286678320332,\n",
              "               0.030848191040591565,\n",
              "               0.030584448122123454,\n",
              "               0.031143533354397106,\n",
              "               0.03032348709680768,\n",
              "               0.029610231444241488,\n",
              "               0.02841943999375246,\n",
              "               0.027227922722673516,\n",
              "               0.026409753350802145,\n",
              "               0.027207365518706256,\n",
              "               0.027096773797823166,\n",
              "               0.027202912323458308,\n",
              "               0.027535387670626747,\n",
              "               0.026757333302361033,\n",
              "               0.026974944291148977,\n",
              "               0.02646427933489046,\n",
              "               0.026819168280984833,\n",
              "               0.027180249919997006,\n",
              "               0.026743129711768482,\n",
              "               0.02659686547540581,\n",
              "               0.02694436310226238,\n",
              "               0.026602094269971847,\n",
              "               0.026891920408535972,\n",
              "               0.02673994113629627,\n",
              "               0.026982503250177262,\n",
              "               0.02738325856079346,\n",
              "               0.027503563484496243,\n",
              "               0.026798477182973245,\n",
              "               0.026614056490417065,\n",
              "               0.026485402790719516,\n",
              "               0.02624972374319436,\n",
              "               0.026442827278975047,\n",
              "               0.026731122758415656,\n",
              "               0.026858538483643037,\n",
              "               0.026859572901402014,\n",
              "               0.027400848850759694,\n",
              "               0.026806099545129733,\n",
              "               0.02645474223444133,\n",
              "               0.026066867243560592,\n",
              "               0.02611169469479222,\n",
              "               0.025867722373907092,\n",
              "               0.027755193498661613,\n",
              "               0.028488565370756384,\n",
              "               0.028460586181868384,\n",
              "               0.028875354490301788,\n",
              "               0.028864943641661416,\n",
              "               0.028815984551385673,\n",
              "               0.02802696300071567,\n",
              "               0.028114914596571807,\n",
              "               0.02823181086619095,\n",
              "               0.027922190298036803,\n",
              "               0.02840508292114878,\n",
              "               0.028719368100476428,\n",
              "               0.028058263406264265,\n",
              "               0.02855844763829843,\n",
              "               0.02779372966990899,\n",
              "               0.027941444355354488,\n",
              "               0.028434116241350206,\n",
              "               0.027106687927150947,\n",
              "               0.027688392924951163,\n",
              "               0.027921734550110402,\n",
              "               0.02789882363213361,\n",
              "               0.0280749695837689,\n",
              "               0.02733352772532187,\n",
              "               0.026839555515483973,\n",
              "               0.027302160378092986,\n",
              "               0.0270753512583482,\n",
              "               0.0274126867449563,\n",
              "               0.027928555166006272,\n",
              "               0.027875060006243763,\n",
              "               0.027532924875459202,\n",
              "               0.02796036524261725,\n",
              "               0.028429486872297044,\n",
              "               0.028204428467783,\n",
              "               0.028259721391374466,\n",
              "               0.028232221879562397,\n",
              "               0.028210831654865237,\n",
              "               0.028136145009954507,\n",
              "               0.027609940952338263,\n",
              "               0.027762766540826975,\n",
              "               0.02860089680893029,\n",
              "               0.028745343521127634,\n",
              "               0.029204528385263464,\n",
              "               0.02943758141017286,\n",
              "               0.029947187872842153,\n",
              "               0.03010243169655969,\n",
              "               0.030031253090038203,\n",
              "               0.03043537220019914,\n",
              "               0.030228579128702724,\n",
              "               0.030339457773972883,\n",
              "               0.030562309105605534,\n",
              "               0.03074191553857011,\n",
              "               0.03164822140580737,\n",
              "               0.03211646530883029,\n",
              "               0.03156181737590707,\n",
              "               0.03139040962471758,\n",
              "               0.03151038121636712,\n",
              "               0.031252345777819615,\n",
              "               0.031166210348406324,\n",
              "               0.0315422743033374,\n",
              "               0.031243841373642143,\n",
              "               0.03151667688121675,\n",
              "               0.031185700784382816,\n",
              "               0.031660499099960694,\n",
              "               0.03198617754815154,\n",
              "               0.031928971033143294,\n",
              "               0.031765291579943324,\n",
              "               0.031131519160501855,\n",
              "               0.031182818964341583,\n",
              "               0.031732494553292676,\n",
              "               0.030983050470975673,\n",
              "               0.031419618066069285,\n",
              "               0.03192911867167437,\n",
              "               0.0317426574164391,\n",
              "               0.03192942860690106,\n",
              "               0.0313869041369531,\n",
              "               0.032023199521497764,\n",
              "               0.03260053861630397,\n",
              "               0.032822229124682384,\n",
              "               0.032995774881829976,\n",
              "               0.03339067252649239,\n",
              "               0.03340053387352947,\n",
              "               0.0336717714762507,\n",
              "               0.034006666933612546,\n",
              "               0.03404266303407676,\n",
              "               0.03402668544224486,\n",
              "               0.03446356543544117,\n",
              "               0.033793738402658355,\n",
              "               0.03347250343793129,\n",
              "               0.03362700343748615,\n",
              "               0.033338014945461965,\n",
              "               0.03352328398527118,\n",
              "               0.03406191611789882,\n",
              "               0.03420931438202568,\n",
              "               0.034615554375848706,\n",
              "               0.034668896246720544,\n",
              "               0.03512064039229899,\n",
              "               0.03529003689373078,\n",
              "               0.035118447089272364,\n",
              "               0.03514895354171553],\n",
              "              'train-MultiClass-mean': [1.8215096307156333,\n",
              "               1.6580849070513402,\n",
              "               1.5255839598521803,\n",
              "               1.411572106936087,\n",
              "               1.3279608762438586,\n",
              "               1.254927352999388,\n",
              "               1.1913726829547928,\n",
              "               1.1348701307171212,\n",
              "               1.086190084810726,\n",
              "               1.0406620645362203,\n",
              "               1.0054536726261725,\n",
              "               0.973495426292342,\n",
              "               0.9419461204606177,\n",
              "               0.9121638325678897,\n",
              "               0.8890932440589189,\n",
              "               0.8609764297418216,\n",
              "               0.8375755347671734,\n",
              "               0.8194186102524502,\n",
              "               0.800194224293778,\n",
              "               0.7825609494184294,\n",
              "               0.763842413773649,\n",
              "               0.7475569462351093,\n",
              "               0.7327649438873536,\n",
              "               0.7207610399683689,\n",
              "               0.7078825314623328,\n",
              "               0.6964719121048203,\n",
              "               0.684741116805947,\n",
              "               0.6747712155054605,\n",
              "               0.6632518000621165,\n",
              "               0.6545398722783721,\n",
              "               0.6428620338641206,\n",
              "               0.6335188857375609,\n",
              "               0.6259937997713637,\n",
              "               0.6168172951619106,\n",
              "               0.6104154581836051,\n",
              "               0.6030587678963677,\n",
              "               0.5956623156620626,\n",
              "               0.5886675014914794,\n",
              "               0.5825854270271745,\n",
              "               0.5759663485134504,\n",
              "               0.5693440414856278,\n",
              "               0.5628882717460598,\n",
              "               0.5578434078538674,\n",
              "               0.5514046579906582,\n",
              "               0.5475190073652567,\n",
              "               0.5407603863755769,\n",
              "               0.5355605359039278,\n",
              "               0.5309080153936138,\n",
              "               0.526165301846424,\n",
              "               0.5206563575640614,\n",
              "               0.5170081308029075,\n",
              "               0.513366134950057,\n",
              "               0.507542827415454,\n",
              "               0.5034261125243319,\n",
              "               0.49796044270524686,\n",
              "               0.49399588956591284,\n",
              "               0.4899642796925197,\n",
              "               0.4864081358369627,\n",
              "               0.4828949644193574,\n",
              "               0.47985012993618875,\n",
              "               0.47608710317876807,\n",
              "               0.47307028539326695,\n",
              "               0.46998048274355103,\n",
              "               0.4668430348989531,\n",
              "               0.4624265415188793,\n",
              "               0.459223026681161,\n",
              "               0.45728136560187127,\n",
              "               0.45330493323829235,\n",
              "               0.4506707613372691,\n",
              "               0.44698507024636625,\n",
              "               0.44363747393993375,\n",
              "               0.44120717639506885,\n",
              "               0.4385679772351301,\n",
              "               0.4354642543830141,\n",
              "               0.4321271311163137,\n",
              "               0.42999529949484877,\n",
              "               0.4276524451814117,\n",
              "               0.42445915322200145,\n",
              "               0.421441638581709,\n",
              "               0.41816884187226727,\n",
              "               0.4160882729569086,\n",
              "               0.41306365488532776,\n",
              "               0.4105030852748202,\n",
              "               0.4080919358813764,\n",
              "               0.4055656811907899,\n",
              "               0.40306286936520447,\n",
              "               0.3997619938412708,\n",
              "               0.3975005920736275,\n",
              "               0.3949521398306644,\n",
              "               0.39184010240249373,\n",
              "               0.3890464879295787,\n",
              "               0.3869759502398147,\n",
              "               0.38501464363743093,\n",
              "               0.3828330797617725,\n",
              "               0.3806668469264949,\n",
              "               0.3779257495638689,\n",
              "               0.37605675750066586,\n",
              "               0.3736297373947643,\n",
              "               0.37151392971661085,\n",
              "               0.36873534993163276,\n",
              "               0.36682769837306384,\n",
              "               0.36502679228123025,\n",
              "               0.36332853375342494,\n",
              "               0.36105319325214635,\n",
              "               0.3589522364705547,\n",
              "               0.35619217677335263,\n",
              "               0.3540107691793788,\n",
              "               0.35184363062589535,\n",
              "               0.34976855874389473,\n",
              "               0.34805223539352426,\n",
              "               0.3467316498006006,\n",
              "               0.3446106221991487,\n",
              "               0.34304242049218137,\n",
              "               0.34169979982211673,\n",
              "               0.3390388177862211,\n",
              "               0.3369519960337501,\n",
              "               0.3355321497893413,\n",
              "               0.33389536792323643,\n",
              "               0.33192319128066244,\n",
              "               0.33057793067109537,\n",
              "               0.3285597737329133,\n",
              "               0.32726350492868267,\n",
              "               0.32588079815828147,\n",
              "               0.3245199038152629,\n",
              "               0.3231418781839766,\n",
              "               0.3218256316534957,\n",
              "               0.3205559572002017,\n",
              "               0.3191542559235006,\n",
              "               0.317364376684263,\n",
              "               0.3156718278137898,\n",
              "               0.31362899304408093,\n",
              "               0.31239673769130255,\n",
              "               0.3110243369065777,\n",
              "               0.3091822886818621,\n",
              "               0.307591024803654,\n",
              "               0.30617225004079623,\n",
              "               0.30479381224507834,\n",
              "               0.3031257512114867,\n",
              "               0.3015570595977579,\n",
              "               0.2998631729229127,\n",
              "               0.29800201177944935,\n",
              "               0.2959233855046664,\n",
              "               0.294526627072315,\n",
              "               0.29340911016358445,\n",
              "               0.2921350181493673,\n",
              "               0.29037401100531324,\n",
              "               0.28839355775220404,\n",
              "               0.28705642738421344,\n",
              "               0.285676954013443,\n",
              "               0.28481993763687297,\n",
              "               0.28362965610847696,\n",
              "               0.2821196912018831,\n",
              "               0.28081299275853266,\n",
              "               0.279899722215795,\n",
              "               0.2787704351885982,\n",
              "               0.2772309485734628,\n",
              "               0.2762866249573694,\n",
              "               0.27495715879406113,\n",
              "               0.2737877640569017,\n",
              "               0.2727503824956042,\n",
              "               0.2716208098323268,\n",
              "               0.2705458130954872,\n",
              "               0.26962891131582684,\n",
              "               0.26846633479160414,\n",
              "               0.26730417413623164,\n",
              "               0.2662613427163948,\n",
              "               0.26480359778040735,\n",
              "               0.26306060031849027,\n",
              "               0.262391973184152,\n",
              "               0.26132213499979634,\n",
              "               0.26005055283845613,\n",
              "               0.25929165677221744,\n",
              "               0.25793289184740736,\n",
              "               0.25708103905248986,\n",
              "               0.2562429556174412,\n",
              "               0.2551992351115812,\n",
              "               0.25420495534764637,\n",
              "               0.25354039063334805,\n",
              "               0.2526944685406431,\n",
              "               0.25188866644803165,\n",
              "               0.25071351193697716,\n",
              "               0.24981090255532687,\n",
              "               0.24824663171835773,\n",
              "               0.24731228144184744,\n",
              "               0.24635244571106737,\n",
              "               0.24552101646418403,\n",
              "               0.24421765840255963,\n",
              "               0.2429479526728688,\n",
              "               0.24184523964915638,\n",
              "               0.2407488718293511,\n",
              "               0.2399252548689198,\n",
              "               0.23878649147927256,\n",
              "               0.23755705512393066,\n",
              "               0.23648113435910745,\n",
              "               0.23564494856103038,\n",
              "               0.23465186090533552,\n",
              "               0.2336071315621858,\n",
              "               0.23251328013386466,\n",
              "               0.23102665196101238,\n",
              "               0.2299504550916749],\n",
              "              'train-MultiClass-std': [0.013749848890835758,\n",
              "               0.008461921720770633,\n",
              "               0.0044961350117139936,\n",
              "               0.002613095121380391,\n",
              "               0.00695615542728902,\n",
              "               0.0035725595001182787,\n",
              "               0.001131961414050487,\n",
              "               0.0037624853365621535,\n",
              "               0.002129123910612892,\n",
              "               0.0032033442705679204,\n",
              "               0.00043182433335065196,\n",
              "               0.00422849086812395,\n",
              "               0.0015862879819223885,\n",
              "               0.00405189086716239,\n",
              "               0.005796711698870446,\n",
              "               0.005970440100179013,\n",
              "               0.007046621908873915,\n",
              "               0.007880267402969083,\n",
              "               0.008579976825342988,\n",
              "               0.006632164867616346,\n",
              "               0.006524203891444508,\n",
              "               0.008580445337475906,\n",
              "               0.009793241004897027,\n",
              "               0.008687668520989577,\n",
              "               0.008928209737318787,\n",
              "               0.008927136455797461,\n",
              "               0.011225723560283875,\n",
              "               0.012782998870067445,\n",
              "               0.011986185462736386,\n",
              "               0.01106746396147662,\n",
              "               0.011129965593640318,\n",
              "               0.010354284871476297,\n",
              "               0.00910001159674137,\n",
              "               0.010375682752521254,\n",
              "               0.008541408913519065,\n",
              "               0.008023819757749967,\n",
              "               0.007823590593547564,\n",
              "               0.007588009890211568,\n",
              "               0.007981947814370739,\n",
              "               0.009478367686619235,\n",
              "               0.009194034228036375,\n",
              "               0.009278069355468046,\n",
              "               0.007986386084419733,\n",
              "               0.008117307288312657,\n",
              "               0.007306514411601208,\n",
              "               0.007806835681403807,\n",
              "               0.006988921417654217,\n",
              "               0.006824727256261,\n",
              "               0.006647102813828709,\n",
              "               0.0050893176482515795,\n",
              "               0.004378295536291756,\n",
              "               0.004176980459884297,\n",
              "               0.0034566861561732467,\n",
              "               0.0036955724572676884,\n",
              "               0.0038799748008450196,\n",
              "               0.0034940864516441977,\n",
              "               0.002679666201896814,\n",
              "               0.002540245701955169,\n",
              "               0.0031648216731483786,\n",
              "               0.0029802548803240765,\n",
              "               0.0023147401881150665,\n",
              "               0.0019509184050028252,\n",
              "               0.0016022905636633726,\n",
              "               0.0024379463534952954,\n",
              "               0.002307279012282488,\n",
              "               0.0023141529276258202,\n",
              "               0.0029092447410427,\n",
              "               0.0028656833556486316,\n",
              "               0.0032229501167900638,\n",
              "               0.002641242705792984,\n",
              "               0.0029953483164695174,\n",
              "               0.0017846140387926645,\n",
              "               0.000763360817811522,\n",
              "               0.0013228107010665755,\n",
              "               0.001962865960459779,\n",
              "               0.00259131563946477,\n",
              "               0.0026335190657295103,\n",
              "               0.001549604504981038,\n",
              "               0.0011828505266241998,\n",
              "               0.001917995935164449,\n",
              "               0.0018712058844807054,\n",
              "               0.0015048048317054617,\n",
              "               0.0008757852918036501,\n",
              "               0.001623274305149435,\n",
              "               0.0016794533393924332,\n",
              "               0.0019995433551019824,\n",
              "               0.0016269570650055973,\n",
              "               0.0016107489804898754,\n",
              "               0.0017974537387288607,\n",
              "               0.000543315161073468,\n",
              "               0.0008868744060263414,\n",
              "               0.0012504904522948254,\n",
              "               0.001633622105166538,\n",
              "               0.002179255131856973,\n",
              "               0.0018354713057179791,\n",
              "               0.0024745219388423697,\n",
              "               0.0024463184486584206,\n",
              "               0.002735435459143877,\n",
              "               0.002544114713142975,\n",
              "               0.0021473609630771337,\n",
              "               0.0018150381296054437,\n",
              "               0.0011397804812744233,\n",
              "               0.0009518467920464461,\n",
              "               0.0010198463862162446,\n",
              "               0.0005023694436403788,\n",
              "               0.0004976174440743482,\n",
              "               0.00027589955840581917,\n",
              "               0.00011517099899623819,\n",
              "               0.000510212691612986,\n",
              "               0.0005032727281336766,\n",
              "               0.00036110995251413167,\n",
              "               0.00016705722725009897,\n",
              "               0.0004951159412944988,\n",
              "               0.0008116057401176,\n",
              "               0.0018406588671941427,\n",
              "               0.0017671089554417792,\n",
              "               0.0018173574140096114,\n",
              "               0.00298614952546638,\n",
              "               0.002698171863746647,\n",
              "               0.0025946108213583943,\n",
              "               0.0032112787364133445,\n",
              "               0.0032430833480921713,\n",
              "               0.0031572132678964427,\n",
              "               0.003246280839696048,\n",
              "               0.003400065645186491,\n",
              "               0.003183101562991041,\n",
              "               0.003389489145371857,\n",
              "               0.003310690585314576,\n",
              "               0.0029604895543958063,\n",
              "               0.0031395601436335313,\n",
              "               0.0032984774504895478,\n",
              "               0.003343788939327822,\n",
              "               0.0028906512099500558,\n",
              "               0.0026915934120678585,\n",
              "               0.0033361459069473913,\n",
              "               0.0036896437352531954,\n",
              "               0.0037425211808158674,\n",
              "               0.003352071679855657,\n",
              "               0.0032847302848305502,\n",
              "               0.003281925628427119,\n",
              "               0.003847170770202105,\n",
              "               0.0040592451604736105,\n",
              "               0.00388125824196886,\n",
              "               0.004093839133292123,\n",
              "               0.004007517030872827,\n",
              "               0.004473717627198072,\n",
              "               0.0050493931218058945,\n",
              "               0.00504853711353781,\n",
              "               0.005482482483792664,\n",
              "               0.005660887742902766,\n",
              "               0.005570014096807292,\n",
              "               0.005166874101248257,\n",
              "               0.005490270459399071,\n",
              "               0.0053857292344581965,\n",
              "               0.005208015001747593,\n",
              "               0.005013504429366663,\n",
              "               0.004810904957341375,\n",
              "               0.0046678070622316525,\n",
              "               0.004860105108241062,\n",
              "               0.004822442795226688,\n",
              "               0.0048035238278328,\n",
              "               0.004882843752440384,\n",
              "               0.0049859067434667335,\n",
              "               0.005057844744978482,\n",
              "               0.005276727319513321,\n",
              "               0.0053464461783286005,\n",
              "               0.005192347689007062,\n",
              "               0.005175012954326259,\n",
              "               0.005316331291827465,\n",
              "               0.005848566773528106,\n",
              "               0.005618974577693157,\n",
              "               0.005521690327507961,\n",
              "               0.0052177615499460475,\n",
              "               0.0055738146923439095,\n",
              "               0.005538628361781953,\n",
              "               0.005741281031905512,\n",
              "               0.005685292547118027,\n",
              "               0.0056127008621070515,\n",
              "               0.005777622144818482,\n",
              "               0.005889697177458493,\n",
              "               0.00557916441178378,\n",
              "               0.005742209766883656,\n",
              "               0.005766050955172618,\n",
              "               0.0058458916121713654,\n",
              "               0.005825221657377649,\n",
              "               0.005634045138649222,\n",
              "               0.0052550118665678595,\n",
              "               0.005722046856642444,\n",
              "               0.005683003574150133,\n",
              "               0.005510491753429378,\n",
              "               0.005338205890685776,\n",
              "               0.005334970981279304,\n",
              "               0.005722167853895792,\n",
              "               0.005661524420537224,\n",
              "               0.0056795269929464575,\n",
              "               0.005903845403348988,\n",
              "               0.005534154560238508,\n",
              "               0.005948664584259438,\n",
              "               0.005851363023155353,\n",
              "               0.005708948354565176]}),\n",
              " 'params': {'depth': 4,\n",
              "  'l2_leaf_reg': 1.6666666666666667,\n",
              "  'learning_rate': 0.1}}"
            ]
          },
          "metadata": {},
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-JewPaMkMmas",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0d4252cd-bad3-4a01-fd88-a450418af024"
      },
      "source": [
        "from sklearn.metrics import accuracy_score\n",
        "y_train = list(map(int,y_train))\n",
        "y_test = list(map(int,y_test))\n",
        "y_train_predicted = boosting_model.predict(X_train_origin)\n",
        "y_test_predicted = boosting_model.predict(X_test_origin)\n",
        "train_accuracy = accuracy_score(y_train, y_train_predicted)\n",
        "test_accuracy = accuracy_score(y_test, y_test_predicted)\n",
        "print('train: ', train_accuracy)\n",
        "print('test: ', test_accuracy)"
      ],
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "train:  0.9455337690631809\n",
            "test:  0.7304347826086957\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "I5oO77m1Mmas"
      },
      "source": [
        "# РЕЗУЛЬТАТ"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "i6B7aO2rMmas",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "fc9f88fc-1906-4def-aa7a-bbe6e1b434d8"
      },
      "source": [
        "path = r'drive/MyDrive/kaggle_data' \n",
        "data = {}\n",
        "\n",
        "Data = []\n",
        "Target = []\n",
        "\n",
        "i=0\n",
        "for dir_entry in sorted(os.listdir(path)):\n",
        "    dir_entry_path = os.path.join(path, dir_entry)\n",
        "    if os.path.isfile(dir_entry_path):\n",
        "        i+=1\n",
        "        with open(dir_entry_path, 'r') as my_file:\n",
        "            print(dir_entry_path.split(\"/\")[-1])\n",
        "            try:\n",
        "                df = pd.read_csv(my_file, delimiter=';')\n",
        "                if df.shape[1] == 5:\n",
        "                    Data.append(df)\n",
        "                    Target.append(dir_entry_path.split(\"/\")[-1])\n",
        "            except UnicodeDecodeError:\n",
        "                print(dir_entry_path.split(\"/\")[-1])\n",
        "                pass\n",
        "\n",
        "for dir_entry in sorted(os.listdir(path)):\n",
        "    dir_entry_path = os.path.join(path, dir_entry)\n",
        "    if os.path.isfile(dir_entry_path):\n",
        "        i+=1\n",
        "        with open(dir_entry_path, 'r') as my_file:\n",
        "            print(dir_entry_path.split(\"/\")[-1])\n",
        "            try:\n",
        "                df = pd.read_csv(my_file, delimiter=',')\n",
        "                if df.shape[1] == 5:\n",
        "                    Data.append(df)\n",
        "                    Target.append(dir_entry_path.split(\"/\")[-1])\n",
        "            except UnicodeDecodeError:\n",
        "                print(dir_entry_path.split(\"/\")[-1])\n",
        "                pass"
      ],
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "track_0.csv\n",
            "track_1.csv\n",
            "track_10.csv\n",
            "track_100.csv\n",
            "track_101.csv\n",
            "track_102.csv\n",
            "track_103.csv\n",
            "track_104.csv\n",
            "track_105.csv\n",
            "track_106.csv\n",
            "track_107.csv\n",
            "track_108.csv\n",
            "track_109.csv\n",
            "track_11.csv\n",
            "track_110.csv\n",
            "track_111.csv\n",
            "track_112.csv\n",
            "track_113.csv\n",
            "track_114.csv\n",
            "track_115.csv\n",
            "track_116.csv\n",
            "track_117.csv\n",
            "track_118.csv\n",
            "track_119.csv\n",
            "track_12.csv\n",
            "track_120.csv\n",
            "track_121.csv\n",
            "track_122.csv\n",
            "track_123.csv\n",
            "track_124.csv\n",
            "track_125.csv\n",
            "track_126.csv\n",
            "track_127.csv\n",
            "track_128.csv\n",
            "track_129.csv\n",
            "track_13.csv\n",
            "track_130.csv\n",
            "track_131.csv\n",
            "track_132.csv\n",
            "track_133.csv\n",
            "track_134.csv\n",
            "track_135.csv\n",
            "track_136.csv\n",
            "track_137.csv\n",
            "track_138.csv\n",
            "track_139.csv\n",
            "track_14.csv\n",
            "track_140.csv\n",
            "track_141.csv\n",
            "track_142.csv\n",
            "track_143.csv\n",
            "track_144.csv\n",
            "track_145.csv\n",
            "track_15.csv\n",
            "track_16.csv\n",
            "track_17.csv\n",
            "track_18.csv\n",
            "track_19.csv\n",
            "track_2.csv\n",
            "track_20.csv\n",
            "track_21.csv\n",
            "track_22.csv\n",
            "track_23.csv\n",
            "track_24.csv\n",
            "track_25.csv\n",
            "track_26.csv\n",
            "track_27.csv\n",
            "track_28.csv\n",
            "track_29.csv\n",
            "track_3.csv\n",
            "track_30.csv\n",
            "track_31.csv\n",
            "track_32.csv\n",
            "track_33.csv\n",
            "track_34.csv\n",
            "track_35.csv\n",
            "track_36.csv\n",
            "track_37.csv\n",
            "track_38.csv\n",
            "track_39.csv\n",
            "track_4.csv\n",
            "track_40.csv\n",
            "track_41.csv\n",
            "track_42.csv\n",
            "track_43.csv\n",
            "track_44.csv\n",
            "track_45.csv\n",
            "track_46.csv\n",
            "track_47.csv\n",
            "track_48.csv\n",
            "track_49.csv\n",
            "track_5.csv\n",
            "track_50.csv\n",
            "track_51.csv\n",
            "track_52.csv\n",
            "track_53.csv\n",
            "track_54.csv\n",
            "track_55.csv\n",
            "track_56.csv\n",
            "track_57.csv\n",
            "track_58.csv\n",
            "track_59.csv\n",
            "track_6.csv\n",
            "track_60.csv\n",
            "track_61.csv\n",
            "track_62.csv\n",
            "track_63.csv\n",
            "track_64.csv\n",
            "track_65.csv\n",
            "track_66.csv\n",
            "track_67.csv\n",
            "track_68.csv\n",
            "track_69.csv\n",
            "track_7.csv\n",
            "track_70.csv\n",
            "track_71.csv\n",
            "track_72.csv\n",
            "track_73.csv\n",
            "track_74.csv\n",
            "track_75.csv\n",
            "track_76.csv\n",
            "track_77.csv\n",
            "track_78.csv\n",
            "track_79.csv\n",
            "track_8.csv\n",
            "track_80.csv\n",
            "track_81.csv\n",
            "track_82.csv\n",
            "track_83.csv\n",
            "track_84.csv\n",
            "track_85.csv\n",
            "track_86.csv\n",
            "track_87.csv\n",
            "track_88.csv\n",
            "track_89.csv\n",
            "track_9.csv\n",
            "track_90.csv\n",
            "track_91.csv\n",
            "track_92.csv\n",
            "track_93.csv\n",
            "track_94.csv\n",
            "track_95.csv\n",
            "track_96.csv\n",
            "track_97.csv\n",
            "track_98.csv\n",
            "track_99.csv\n",
            "track_0.csv\n",
            "track_1.csv\n",
            "track_10.csv\n",
            "track_100.csv\n",
            "track_101.csv\n",
            "track_102.csv\n",
            "track_103.csv\n",
            "track_104.csv\n",
            "track_105.csv\n",
            "track_106.csv\n",
            "track_107.csv\n",
            "track_108.csv\n",
            "track_109.csv\n",
            "track_11.csv\n",
            "track_110.csv\n",
            "track_111.csv\n",
            "track_112.csv\n",
            "track_113.csv\n",
            "track_114.csv\n",
            "track_115.csv\n",
            "track_116.csv\n",
            "track_117.csv\n",
            "track_118.csv\n",
            "track_119.csv\n",
            "track_12.csv\n",
            "track_120.csv\n",
            "track_121.csv\n",
            "track_122.csv\n",
            "track_123.csv\n",
            "track_124.csv\n",
            "track_125.csv\n",
            "track_126.csv\n",
            "track_127.csv\n",
            "track_128.csv\n",
            "track_129.csv\n",
            "track_13.csv\n",
            "track_130.csv\n",
            "track_131.csv\n",
            "track_132.csv\n",
            "track_133.csv\n",
            "track_134.csv\n",
            "track_135.csv\n",
            "track_136.csv\n",
            "track_137.csv\n",
            "track_138.csv\n",
            "track_139.csv\n",
            "track_14.csv\n",
            "track_140.csv\n",
            "track_141.csv\n",
            "track_142.csv\n",
            "track_143.csv\n",
            "track_144.csv\n",
            "track_145.csv\n",
            "track_15.csv\n",
            "track_16.csv\n",
            "track_17.csv\n",
            "track_18.csv\n",
            "track_19.csv\n",
            "track_2.csv\n",
            "track_20.csv\n",
            "track_21.csv\n",
            "track_22.csv\n",
            "track_23.csv\n",
            "track_24.csv\n",
            "track_25.csv\n",
            "track_26.csv\n",
            "track_27.csv\n",
            "track_28.csv\n",
            "track_29.csv\n",
            "track_3.csv\n",
            "track_30.csv\n",
            "track_31.csv\n",
            "track_32.csv\n",
            "track_33.csv\n",
            "track_34.csv\n",
            "track_35.csv\n",
            "track_36.csv\n",
            "track_37.csv\n",
            "track_38.csv\n",
            "track_39.csv\n",
            "track_4.csv\n",
            "track_40.csv\n",
            "track_41.csv\n",
            "track_42.csv\n",
            "track_43.csv\n",
            "track_44.csv\n",
            "track_45.csv\n",
            "track_46.csv\n",
            "track_47.csv\n",
            "track_48.csv\n",
            "track_49.csv\n",
            "track_5.csv\n",
            "track_50.csv\n",
            "track_51.csv\n",
            "track_52.csv\n",
            "track_53.csv\n",
            "track_54.csv\n",
            "track_55.csv\n",
            "track_56.csv\n",
            "track_57.csv\n",
            "track_58.csv\n",
            "track_59.csv\n",
            "track_6.csv\n",
            "track_60.csv\n",
            "track_61.csv\n",
            "track_62.csv\n",
            "track_63.csv\n",
            "track_64.csv\n",
            "track_65.csv\n",
            "track_66.csv\n",
            "track_67.csv\n",
            "track_68.csv\n",
            "track_69.csv\n",
            "track_7.csv\n",
            "track_70.csv\n",
            "track_71.csv\n",
            "track_72.csv\n",
            "track_73.csv\n",
            "track_74.csv\n",
            "track_75.csv\n",
            "track_76.csv\n",
            "track_77.csv\n",
            "track_78.csv\n",
            "track_79.csv\n",
            "track_8.csv\n",
            "track_80.csv\n",
            "track_81.csv\n",
            "track_82.csv\n",
            "track_83.csv\n",
            "track_84.csv\n",
            "track_85.csv\n",
            "track_86.csv\n",
            "track_87.csv\n",
            "track_88.csv\n",
            "track_89.csv\n",
            "track_9.csv\n",
            "track_90.csv\n",
            "track_91.csv\n",
            "track_92.csv\n",
            "track_93.csv\n",
            "track_94.csv\n",
            "track_95.csv\n",
            "track_96.csv\n",
            "track_97.csv\n",
            "track_98.csv\n",
            "track_99.csv\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "md1oDwazMmas",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 49
        },
        "outputId": "30021b95-b551-4b59-8e65-4565b3033ccb"
      },
      "source": [
        "Data_test = pd.DataFrame(data = {'Ampl':[], 'Moving_x':[], 'Moving_y':[],'Moving_z':[], 'max_freq_a':[],\n",
        "                                  'max_freq_x':[], 'max_freq_y':[],'max_freq_z':[],\n",
        "                                  'mean_freq_x':[], 'mean_freq_y':[],'mean_freq_z':[]})\n",
        "Data_test"
      ],
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Ampl</th>\n",
              "      <th>Moving_x</th>\n",
              "      <th>Moving_y</th>\n",
              "      <th>Moving_z</th>\n",
              "      <th>max_freq_a</th>\n",
              "      <th>max_freq_x</th>\n",
              "      <th>max_freq_y</th>\n",
              "      <th>max_freq_z</th>\n",
              "      <th>mean_freq_x</th>\n",
              "      <th>mean_freq_y</th>\n",
              "      <th>mean_freq_z</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "Empty DataFrame\n",
              "Columns: [Ampl, Moving_x, Moving_y, Moving_z, max_freq_a, max_freq_x, max_freq_y, max_freq_z, mean_freq_x, mean_freq_y, mean_freq_z]\n",
              "Index: []"
            ]
          },
          "metadata": {},
          "execution_count": 36
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5s-etB3TMmat"
      },
      "source": [
        "def max_x_by_y(x, y):\n",
        "    max_y = 0\n",
        "    res = x[0]\n",
        "    for i in range(0, len(y)):\n",
        "        if y[i] > max_y and x[i] <= 30 and y[i] <= 0.1:\n",
        "            res = x[i]\n",
        "            max_y = y[i]\n",
        "    return res\n",
        "\n",
        "def process_data(df, comma=True, cut=True, name = \"\", a=-1, b=-1, answer=-1):\n",
        "#     fig, ((ax1, ax2, ax3),(ax4, ax5, ax6),(ax7, ax8, ax9)) = plt.subplots(nrows=3, ncols=3, figsize=(15,10))\n",
        "    st = 0\n",
        "    end = len(df)\n",
        "    if comma is True:\n",
        "        df = df.applymap(lambda x: str(x).replace(',','.'))\n",
        "        try:\n",
        "            df['gFx'] = df['gFx'].astype(float)\n",
        "            df['gFy'] = df['gFy'].astype(float)\n",
        "            df['gFz'] = df['gFz'].astype(float)\n",
        "        except :\n",
        "            return -1\n",
        "        try:\n",
        "            df['time'] = df['time'].astype(float)\n",
        "            # определим частоту\n",
        "            freqs = np.array(df.time[1:]) - np.array(df.time[:-1])\n",
        "            freq = 1/np.mean(freqs)\n",
        "        except:\n",
        "            freq = 250\n",
        "        \n",
        "#     print(name)\n",
        "    # обрезаем начало и конец трека\n",
        "    try:\n",
        "        duration = max(df.time)\n",
        "        tmp = df[(df.time > 5) & (df.time < duration - 5)]\n",
        "        if len(tmp) != 0:\n",
        "            df = tmp\n",
        "    except:\n",
        "        pass\n",
        "    \n",
        "    \n",
        "#     ax1.plot(df.time, df.iloc[st:end]['gFx'],c='g')\n",
        "#     ax1.plot(df.time, df.iloc[st:end]['gFy'],c='r')\n",
        "#     ax1.plot(df.time, df.iloc[st:end]['gFz'],c='b')\n",
        "#     ax1.set_title('gFx, gFy, gFz по времени')\n",
        "    \n",
        "#        show()\n",
        "########################################################################        \n",
        "#integration\n",
        "\n",
        "#вычисляем средний вектор ускорения по треку\n",
        "\n",
        "    mx = df.iloc[st:end]['gFx'].values.mean() \n",
        "    my = df.iloc[st:end]['gFy'].values.mean() \n",
        "    mz = df.iloc[st:end]['gFz'].values.mean() \n",
        "    \n",
        "#находим матрицу поворота этого вектора к вектору (0,0,1)\n",
        "\n",
        "    Vec = [mx,my,mz]\n",
        "    Point = [0, 0, 1]\n",
        "    mat = rotation_matrix_from_vectors(Vec, Point)\n",
        "    \n",
        "#каждую точку трека поворачиваем на эту матрицу\n",
        "\n",
        "    new_x, new_y, new_z = rotate(df.iloc[st:end]['gFx'].values, df.iloc[st:end]['gFy'].values, df.iloc[st:end]['gFz'].values, mat)\n",
        "\n",
        "#проверяем, что новые средние равны примерно (0,0,1). Если это не так, значит, телефон часто поворачивался при движении, и нам не поможет это преобразование\n",
        "\n",
        "#     print('New means:', mean(new_x), mean(new_y), mean(new_z))\n",
        "\n",
        "#делим на 250*250 (это нужно было еще при интегрировании)\n",
        "    new_x = [elem / (freq**2) for elem in new_x]\n",
        "    new_y = [elem / (freq**2) for elem in new_y]\n",
        "#из ускорения по z вычитаем 1 (g), чтобы убрать влияние силы тяжести и оставить только ускорение по z\n",
        "    new_z = [(elem-1)/(freq**2) for elem in new_z]\n",
        "    \n",
        "#дважды интегрируем ускорение, чтобы получить перемещение вдоль каждой оси\n",
        "\n",
        "    int_x = integrate(integrate(new_x))\n",
        "#     ax7.plot(int_x)\n",
        "#     ax7.set_title(\"Перемещение по x\")\n",
        "    moving_x = int_x[-1]\n",
        "    \n",
        "    int_y = integrate(integrate(new_y))\n",
        "#     ax8.plot(int_y)\n",
        "#     ax8.set_title(\"Перемещение по y\")\n",
        "    moving_y = int_y[-1]\n",
        "    \n",
        "    int_z = integrate(integrate(new_z))\n",
        "#     ax9.plot(int_z)\n",
        "#     ax9.set_title(\"Перемещение по z\")\n",
        "    moving_z = int_z[-1]\n",
        "\n",
        "########################################################################        \n",
        "#преобразование Фурье\n",
        "########################################################################        \n",
        "\n",
        "    Fs = freq #частота сбора данных\n",
        "    y = df.iloc[st:end]['gFx'].values\n",
        "    n = len(y) # length of the signal\n",
        "    k = np.arange(n)\n",
        "    T = n/Fs\n",
        "    frq = k/T # two sides frequency range\n",
        "    frq = frq[:len(frq)//2] # one side frequency range\n",
        "\n",
        "    Y = np.fft.fft(y)/n # dft and normalization\n",
        "    Y = Y[:n//2]\n",
        "    \n",
        "    yabs = abs(Y)\n",
        "    \n",
        "    Min = 0\n",
        "    \n",
        "#     ax4.plot(frq,yabs) # plotting the spectrum\n",
        "    max_frq_x = max_x_by_y(frq,yabs)\n",
        "    mean_frq_x = np.mean(frq)\n",
        "#     ax4.set_xlim([0,30]) #очень большие частоты нам не нужны\n",
        "#     ax4.set_ylim([Min,0.1]) #не смотрим на близкие к нулю величины частот\n",
        "#     ax4.set_title(\"Частоты по x\")\n",
        "\n",
        "    \n",
        "    y = df.iloc[st:end]['gFy'].values\n",
        "    n = len(y) # length of the signal\n",
        "    k = np.arange(n)\n",
        "    T = n/Fs\n",
        "    frq = k/T # two sides frequency range\n",
        "    frq = frq[:len(frq)//2] # one side frequency range\n",
        "\n",
        "    Y = np.fft.fft(y)/n # dft and normalization\n",
        "    Y = Y[:n//2]\n",
        "    \n",
        "    yabs = abs(Y)\n",
        "    \n",
        "#     ax5.plot(frq,yabs) # plotting the spectrum\n",
        "    max_frq_y = max_x_by_y(frq,yabs)\n",
        "    mean_frq_y = np.mean(frq)\n",
        "#     ax5.set_xlim([0,30])\n",
        "#     ax5.set_ylim([Min,0.1])\n",
        "#     ax5.set_title(\"Частоты по y\")\n",
        "\n",
        "\n",
        "    y = df.iloc[st:end]['gFz'].values\n",
        "    n = len(y) # length of the signal\n",
        "    k = np.arange(n)\n",
        "    T = n/Fs\n",
        "    frq = k/T # two sides frequency range\n",
        "    frq = frq[:len(frq)//2] # one side frequency range\n",
        "\n",
        "    Y = np.fft.fft(y)/n # dft and normalization\n",
        "    Y = Y[:n//2]\n",
        "    \n",
        "    yabs = abs(Y)\n",
        "   \n",
        "#     ax6.plot(frq,yabs) # plotting the spectrum\n",
        "    max_frq_z = max_x_by_y(frq,yabs)\n",
        "    mean_frq_z = np.mean(frq)\n",
        "#     ax6.set_xlim([0,30])\n",
        "#     ax6.set_ylim([Min,0.1])\n",
        "#     ax6.set_title(\"Частоты по z\")\n",
        "\n",
        "\n",
        "    Acc = (df.gFx[st:end] ** 2 + df.gFy[st:end] ** 2 + df.gFz[st:end] ** 2) ** 0.5\n",
        "\n",
        "    y = Acc.values\n",
        "    n = len(y) # length of the signal\n",
        "    k = np.arange(n)\n",
        "    T = n/Fs\n",
        "    frq = k/T # two sides frequency range\n",
        "    frq = frq[:len(frq)//2] # one side frequency range\n",
        "\n",
        "    Y = np.fft.fft(y)/n # dft and normalization\n",
        "    Y = Y[:n//2]\n",
        "    \n",
        "    yabs = abs(Y)\n",
        "    \n",
        "#     plt.plot(frq,yabs) # plotting the spectrum\n",
        "#     xlim([0,30])\n",
        "#     ylim([Min,0.1])\n",
        "#     plt.title('Частоты общего ускорения')\n",
        "    max_frq_a = max_x_by_y(frq,yabs)\n",
        "########################################################################        \n",
        "    \n",
        "    Acc = (df.gFx[st:end] ** 2 + df.gFy[st:end] ** 2 + df.gFz[st:end] ** 2) ** 0.5\n",
        "    amplitude = Acc.max() - Acc.min()\n",
        "#     ax2.plot(Acc)\n",
        "#     ax2.set_title('Общее ускорение')\n",
        "#     print(name)\n",
        "#     plt.show()\n",
        "    \n",
        "#     print(name + ' Амплитуда:', Acc.max()-Acc.min())\n",
        "    track_num = int(name.split('_')[1].split('.')[0])\n",
        "    Data_test.loc[track_num] = [amplitude,abs(moving_x),abs(moving_y),abs(moving_z),\n",
        "                                       max_frq_a,max_frq_x,max_frq_y,max_frq_z,\n",
        "                                       mean_frq_x,mean_frq_y,mean_frq_z]\n",
        "    \n",
        "    return df\n",
        "\n",
        "for df, target, ans in zip(Data,Target,answer):\n",
        "    process_data(df=df, name=target, answer=ans)"
      ],
      "execution_count": 37,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5ClRnAJtMmat",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "df69122e-2a49-4fc7-fd40-bc25ab00d8d0"
      },
      "source": [
        "Data_test = Data_test.sort_index(ascending=True)\n",
        "Data_test.shape"
      ],
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(146, 11)"
            ]
          },
          "metadata": {},
          "execution_count": 38
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ULbeDm9dMmat",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "751efcc9-c92f-40ca-8685-208653f250e5"
      },
      "source": [
        "preds = boosting_model.predict(Data_test)\n",
        "preds = preds.reshape(1,-1)[0].astype(int64)\n",
        "len(preds)"
      ],
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "146"
            ]
          },
          "metadata": {},
          "execution_count": 39
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QE-fQp95Mmat"
      },
      "source": [
        "# Data = torch.tensor(Data_test.values.astype(np.float32)) \n",
        "# preds = torch.argmax(boosting_model.predict_proba(X_test_origin)[:, 1], dim=1)\n",
        "# preds"
      ],
      "execution_count": 40,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SGNrhapdMmau"
      },
      "source": [
        "Создадим таблицу, содержащую номер трека, правильный ответ и предсказание."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GFKXU_V3Mmau",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "716c894d-4dae-4bdd-cd8d-849d8482470f"
      },
      "source": [
        "Res = pd.DataFrame({'track_num' : np.arange(len(preds)), 'action' : preds})\n",
        "Res.shape"
      ],
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(146, 2)"
            ]
          },
          "metadata": {},
          "execution_count": 41
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lEvh2HxUMmau"
      },
      "source": [
        "Res.to_csv(\"4_submit.csv\", index=False)"
      ],
      "execution_count": 42,
      "outputs": []
    }
  ]
}